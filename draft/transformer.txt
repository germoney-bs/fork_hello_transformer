#!/usr/bin/env python
# coding: utf-8

# In[1]:


import torch
from torch import nn
import math
import numpy as np
import torch.nn.functional as F
from copy import copy


# In[2]:


B = 64      # 배치 사이즈
M = 10      # 토큰의 최대 길이
V = 1024    # 토큰의 개수
N = 8       # 멀티헤드 개수
H = 512     # 토큰의 임베딩 사이즈
EXP = 2048  # 확장 사이즈 (FeedForward 클래스 참고)
L = 6       # 인코더/디코더 레이어 개수


# In[3]:


def attention(query, key, value, scale):
    score = torch.matmul(query, key.transpose(-2, -1)) / scale
    prob = F.softmax(score, dim=-1)
    attn = torch.matmul(prob, value)
    return attn


# In[4]:


class MultiHeadAttention(nn.Module):
    def __init__(self, num_head, hidden_size):
        super(MultiHeadAttention, self).__init__()
        self.num_head = num_head
        self.dk = hidden_size // self.num_head
    
    def forward(self, query, key, value):
        '''
        x = torch.rand((B, M, H))
        m = MultiHeadAttention(N, H)
        v = m(x, x, x)
        v.shape  # torch.Size([64, 10, 512])
        '''
        n_batch = query.shape[0]
        query = query.view(n_batch, -1, self.num_head, self.dk).transpose(1, 2)
        key = key.view(n_batch, -1, self.num_head, self.dk).transpose(1, 2)
        value = value.view(n_batch, -1, self.num_head, self.dk).transpose(1, 2)
        
        x = attention(query, key, value, self.dk)
        x = x.transpose(1, 2).contiguous().view(n_batch, -1, self.dk * self.num_head)
        return x


# In[5]:


x = torch.rand((B, M, H))
m = MultiHeadAttention(N, H)
v = m(x, x, x)
v.shape  # torch.Size([64, 10, 512])


# In[6]:


class FeedForward(nn.Module):
    def __init__(self, hidden_size, expand_size):
        super(FeedForward, self).__init__()
        self.linear_1 = nn.Linear(hidden_size, expand_size)
        self.linear_2 = nn.Linear(expand_size, hidden_size)
        
    def forward(self, x):
        '''
        x = torch.rand((B, M, H))
        m = FeedForward(H, EXP)
        v = m(x)
        v.shape  # torch.Size([64, 10, 512])
        '''
        x = self.linear_1(x)
        x = self.linear_2(x)
        return x


# In[7]:


x = torch.rand((B, M, H))
m = FeedForward(H, EXP)
v = m(x)
v.shape  # torch.Size([64, 10, 512])


# In[8]:


class EncoderLayer(nn.Module):
    def __init__(self, hidden_size):
        super(EncoderLayer, self).__init__()
        self.self_attention = MultiHeadAttention(N, hidden_size)
        self.feedforward = FeedForward(hidden_size, EXP)
        
    def forward(self, x):
        '''
        x = torch.rand((B, M, H))
        m = EncoderLayer(H)
        v = m(x)
        v.shape  # torch.Size([64, 10, 512])
        '''
        x = self.self_attention(x, x, x)
        x = self.feedforward(x)
        return x


# In[9]:


x = torch.rand((B, M, H))
m = EncoderLayer(H)
v = m(x)
v.shape  # torch.Size([64, 10, 512])


# In[10]:


class Embedding(nn.Module):
    def __init__(self, n_vocab, hidden_size):
        super(Embedding, self).__init__()
        self.hidden_size = hidden_size
        self.embedding = nn.Embedding(n_vocab, hidden_size)
        
    def forward(self, x):
        '''
        data = np.random.randint(0, V, (B, M))
        x = torch.from_numpy(data)
        m = Embedding(V, H)
        v = m(x)
        v.shape  # torch.Size([64, 10, 512])
        '''
        return self.embedding(x)


# In[11]:


data = np.random.randint(0, V, (B, M))
x = torch.from_numpy(data)
m = Embedding(V, H)
v = m(x)
v.shape  # torch.Size([64, 10, 512])


# In[12]:


class Encoder(nn.Module):
    def __init__(self, n_layers):
        super(Encoder, self).__init__()
        self.n_layers = n_layers
        self.embedding = Embedding(V, H)
        self.layers = [EncoderLayer(H) for i in range(n_layers)]
    
    def forward(self, x):
        '''
        data = np.random.randint(0, V, (B, M))
        x = torch.from_numpy(data)
        m = Encoder(L)
        v = m(x)
        v.shape  # torch.Size([64, 10, 512])
        '''
        x = self.embedding(x)
        for layer in self.layers:
            x = layer(x)
        return x


# In[13]:


data = np.random.randint(0, V, (B, M))
x = torch.from_numpy(data)
m = Encoder(L)
v = m(x)
v.shape  # torch.Size([64, 10, 512])


# In[14]:


class DecoderLayer(nn.Module):
    def __init__(self, n_head, hidden_size):
        super(DecoderLayer, self).__init__()
        self.self_attention = MultiHeadAttention(n_head, hidden_size)
        self.encdec_attention = MultiHeadAttention(n_head, hidden_size)
        self.feedforward = FeedForward(hidden_size, 2048)
        
    def forward(self, x, memory):
        '''
        x = torch.rand((B, M, H))
        mem = copy(x)
        m = DecoderLayer(N, H)
        v = m(x, mem)
        v.shape  # torch.Size([64, 10, 512])
        '''
        x = self.self_attention(x, memory, memory)
        return x


# In[15]:


x = torch.rand((B, M, H))
mem = copy(x)
m = DecoderLayer(N, H)
v = m(x, mem)
v.shape  # torch.Size([64, 10, 512])


# In[16]:


class Decoder(nn.Module):
    def __init__(self, n_layers):
        super(Decoder, self).__init__()
        self.embedding = Embedding(V, H)
        self.layers = [DecoderLayer(N, H) for i in range(n_layers)]
        
    def forward(self, x, memory):
        '''
        data = np.random.randint(0, V, (B, M))
        x = torch.from_numpy(data)
        mem = torch.rand((B, M, H))
        m = Decoder(L)
        v = m(x, mem)
        v.shape  # torch.Size([64, 10, 512])
        '''
        x = self.embedding(x)
        for layer in self.layers:
            x = layer(x, memory)
        return x


# In[17]:


data = np.random.randint(0, V, (B, M))
x = torch.from_numpy(data)
mem = torch.rand((B, M, H))
m = Decoder(L)
v = m(x, mem)
v.shape  # 


# In[18]:


class Transformer(nn.Module):
    def __init__(self):
        super(Transformer, self).__init__()
        self.encoder = Encoder(L)
        self.decoder = Decoder(L)
        
    def forward(self, src, dst):
        '''
        data = np.random.randint(0, V, (B, M))
        src = torch.from_numpy(data)
        data = np.random.randint(0, V, (B, M))
        dst = torch.from_numpy(data)
        src.shape, dst.shape

        m = Transformer()
        v = m(src, dst)
        v.shape  # torch.Size([64, 10, 512])
        '''
        src_encoded = self.encoder(src)
        dst_decoded = self.decoder(dst, src_encoded)
        
        return dst_decoded


# In[19]:


data = np.random.randint(0, V, (B, M))
src = torch.from_numpy(data)
data = np.random.randint(0, V, (B, M))
dst = torch.from_numpy(data)
src.shape, dst.shape

m = Transformer()
v = m(src, dst)
v.shape  # torch.Size([64, 10, 512])


# In[ ]:





