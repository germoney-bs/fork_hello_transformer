{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from model import FewShotInduction\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from torch import optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from criterion import Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'Amazon_few_shot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반드시 do_lower_case=True로 해야 한다.\n",
    "# bert-base-uncased는 영어 데이터를 소문자로 변환해서 학습한 모델이기 때문이다.\n",
    "tokenizer = BertTokenizer.from_pretrained('./bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmazonDataset():\n",
    "    def __init__(self, data_path, tokenizer, dtype):\n",
    "        self.data_path = data_path\n",
    "        self.tokenizer = tokenizer\n",
    "        with open(f'{dtype}.list', 'r') as f:\n",
    "            self.categories = [oneline.rstrip() for oneline in f]\n",
    "        self.support_dataset = {}\n",
    "        self.dataset = {}\n",
    "        for category in tqdm(self.categories, desc='reading categories'):\n",
    "            self.dataset[category] = {\n",
    "                'neg': self.get_data(category, 'neg', dtype),\n",
    "                'pos': self.get_data(category, 'pos', dtype)\n",
    "            }\n",
    "        \n",
    "        if dtype == 'test' or dtype == 'dev':\n",
    "            for category in tqdm(self.categories, desc='reading categories for support'):\n",
    "                self.support_dataset[category] = {\n",
    "                    'neg': self.get_data(category, 'neg', 'train'),\n",
    "                    'pos': self.get_data(category, 'pos', 'train'),\n",
    "                }\n",
    "        \n",
    "    def read_files(self, category, label, dtype):\n",
    "        data = {\n",
    "            'text': [],\n",
    "            'label': []\n",
    "        }\n",
    "        for t in ['t2', 't4', 't5']:\n",
    "            filename = f'{category}.{t}.{dtype}'\n",
    "            with open(os.path.join(self.data_path, filename), 'r') as f:\n",
    "                for oneline in f:\n",
    "                    oneline = oneline.rstrip()\n",
    "                    text = oneline[:-2]\n",
    "                    if int(oneline[-2:]) == 1 and label == 'pos':\n",
    "                        tensor = self.tokenizer(text, return_tensors='pt')\n",
    "                        data['text'].append(tensor['input_ids'][0])\n",
    "                        data['label'].append(1)\n",
    "                    elif int(oneline[-2:]) == -1 and label == 'neg':\n",
    "                        tensor = self.tokenizer(text, return_tensors='pt')\n",
    "                        data['text'].append(tensor['input_ids'][0])\n",
    "                        data['label'].append(0)\n",
    "        data['label'] = torch.tensor(data['label'])\n",
    "        return data\n",
    "    \n",
    "    def get_data(self, category, label, dtype):\n",
    "        data = self.read_files(category, label, dtype)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reading categories: 100%|██████████| 14/14 [02:58<00:00, 12.76s/it]\n",
      "reading categories: 100%|██████████| 5/5 [00:01<00:00,  4.90it/s]\n",
      "reading categories for support: 100%|██████████| 5/5 [00:08<00:00,  1.69s/it]\n",
      "reading categories: 100%|██████████| 4/4 [00:20<00:00,  5.02s/it]\n",
      "reading categories for support: 100%|██████████| 4/4 [00:00<00:00, 15.27it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = AmazonDataset(data_path, tokenizer, 'train')\n",
    "dev_dataset = AmazonDataset(data_path, tokenizer, 'dev')\n",
    "test_dataset = AmazonDataset(data_path, tokenizer, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_text(a_text, b_text):\n",
    "    a_text_len = a_text.shape[1]\n",
    "    b_text_len = b_text.shape[1]\n",
    "\n",
    "    if a_text_len > b_text_len:\n",
    "        b_text = torch.cat([b_text, torch.zeros(b_text.shape[0], a_text_len-b_text_len).long()], dim=1)\n",
    "    else:\n",
    "        a_text = torch.cat([a_text, torch.zeros(a_text.shape[0], b_text_len-a_text_len).long()], dim=1)\n",
    "        \n",
    "    return a_text, b_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmazonDataLoader():\n",
    "    def __init__(self, dataset, batch_size, n_support):\n",
    "        assert n_support % 2 == 0, 'n_support should be multiple of 2'\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.n_support = n_support\n",
    "        self.neg_idx = {k:0 for k in dataset.dataset}\n",
    "        self.pos_idx = {k:0 for k in dataset.dataset}\n",
    "        self.neg_len = {k:len(dataset.dataset[k]['neg']['text']) for k in dataset.dataset}\n",
    "        self.pos_len = {k:len(dataset.dataset[k]['pos']['text']) for k in dataset.dataset}\n",
    "        self.neg = {k:dataset.dataset[k]['neg'] for k in dataset.dataset}\n",
    "        self.pos = {k:dataset.dataset[k]['pos'] for k in dataset.dataset}\n",
    "        self.idx = 0\n",
    "        self.categories = [k for k in dataset.dataset]\n",
    "        \n",
    "        # prepare for test dataset, support dataset should come from \"*.train\"\n",
    "        self.neg_support_idx = {}\n",
    "        self.pos_support_idx = {}\n",
    "        self.neg_support_len = {}\n",
    "        self.pos_support_len = {}\n",
    "        if self.dataset.support_dataset:\n",
    "            self.neg_support_idx = {k:0 for k in self.dataset.support_dataset}\n",
    "            self.pos_support_idx = {k:0 for k in self.dataset.support_dataset}\n",
    "            self.neg_support_len = {k:len(self.dataset.support_dataset[k]['neg']['text']) for k in self.dataset.support_dataset}\n",
    "            self.pos_support_len = {k:len(self.dataset.support_dataset[k]['pos']['text']) for k in self.dataset.support_dataset}\n",
    "        \n",
    "    def get_batch(self):\n",
    "        category = self.categories[self.idx % len(self.categories)]\n",
    "        neg = self.neg[category]\n",
    "        pos = self.pos[category]\n",
    "        neg_start_idx = self.neg_idx[category] % self.neg_len[category]\n",
    "        pos_start_idx = self.pos_idx[category] % self.pos_len[category]\n",
    "        \n",
    "        # prepare negative/positive dataset\n",
    "        neg_text = neg['text'][neg_start_idx:neg_start_idx+(self.batch_size//2)]\n",
    "        pos_text = pos['text'][pos_start_idx:pos_start_idx+(self.batch_size//2)]\n",
    "        neg_label = neg['label'][neg_start_idx:neg_start_idx+(self.batch_size//2)]\n",
    "        pos_label = pos['label'][pos_start_idx:pos_start_idx+(self.batch_size//2)]\n",
    "        self.neg_idx[category] += (self.batch_size//2)\n",
    "        self.pos_idx[category] += (self.batch_size//2)\n",
    "        \n",
    "        if len(neg_text) + len(pos_text) != self.batch_size:\n",
    "            return self.get_batch()\n",
    "            \n",
    "        # padding text dataset\n",
    "        neg_text = pad_sequence([n for n in neg_text], batch_first=True)\n",
    "        pos_text = pad_sequence([p for p in pos_text], batch_first=True)\n",
    "        neg_text, pos_text = pad_text(neg_text, pos_text)\n",
    "            \n",
    "        # prepare support/query text\n",
    "        neg_support_text = neg_text[:self.n_support//2]\n",
    "        pos_support_text = pos_text[:self.n_support//2]\n",
    "        neg_query_text = neg_text[self.n_support//2:]\n",
    "        pos_query_text = pos_text[self.n_support//2:]\n",
    "        \n",
    "        # prepare support/query label\n",
    "        neg_support_label = neg_label[:self.n_support//2]\n",
    "        pos_support_label = pos_label[:self.n_support//2]\n",
    "        neg_query_label = neg_label[self.n_support//2:]\n",
    "        pos_query_label = pos_label[self.n_support//2:]\n",
    "        \n",
    "        # merge support/query text\n",
    "        support_text = torch.cat([neg_support_text, pos_support_text], dim=0)\n",
    "        query_text = torch.cat([neg_query_text, pos_query_text], dim=0)\n",
    "        \n",
    "        # merge support/query label\n",
    "        support_label = torch.cat([neg_support_label, pos_support_label], dim=0)\n",
    "        query_label = torch.cat([neg_query_label, pos_query_label], dim=0)\n",
    "        \n",
    "        # make data and label\n",
    "        data = torch.cat([support_text, query_text], dim=0)\n",
    "        label = torch.cat([support_label, query_label], dim=0)\n",
    "        \n",
    "        # increase category index\n",
    "        self.idx += 1\n",
    "        return data, label\n",
    "    \n",
    "    def get_batch_test(self):\n",
    "        assert self.dataset.support_dataset, 'support_dataset is empty'\n",
    "        \n",
    "        category = self.categories[self.idx % len(self.categories)]\n",
    "        neg = self.neg[category]\n",
    "        pos = self.pos[category]\n",
    "        neg_query_start_idx = self.neg_idx[category] % self.neg_len[category]\n",
    "        pos_query_start_idx = self.pos_idx[category] % self.pos_len[category]\n",
    "        neg_support_start_idx = self.neg_support_idx[category] % self.neg_support_len[category]\n",
    "        pos_support_start_idx = self.pos_support_idx[category] % self.pos_support_len[category]\n",
    "        \n",
    "        # prepare negative/positive support dataset from support_dataset\n",
    "        category_suuport_dataset = self.dataset.support_dataset[category]\n",
    "        neg_support_text = category_suuport_dataset['neg']['text'][neg_support_start_idx:neg_support_start_idx+self.n_support//2]\n",
    "        pos_support_text = category_suuport_dataset['pos']['text'][pos_support_start_idx:pos_support_start_idx+self.n_support//2]\n",
    "        neg_support_label = category_suuport_dataset['neg']['label'][neg_support_start_idx:neg_support_start_idx+self.n_support//2]\n",
    "        pos_support_label = category_suuport_dataset['pos']['label'][pos_support_start_idx:pos_support_start_idx+self.n_support//2]\n",
    "        self.neg_support_idx[category] += (self.n_support//2)\n",
    "        self.pos_support_idx[category] += (self.n_support//2)\n",
    "        \n",
    "        # prepare negative/positive query dataset\n",
    "        neg_query_text = neg['text'][neg_query_start_idx:neg_query_start_idx+(self.batch_size//2 - self.n_support//2)]\n",
    "        pos_query_text = pos['text'][pos_query_start_idx:pos_query_start_idx+(self.batch_size//2 - self.n_support//2)]\n",
    "        neg_query_label = neg['label'][neg_query_start_idx:neg_query_start_idx+(self.batch_size//2 - self.n_support//2)]\n",
    "        pos_query_label = pos['label'][pos_query_start_idx:pos_query_start_idx+(self.batch_size//2 - self.n_support//2)]\n",
    "        self.neg_idx[category] += (self.batch_size//2 - self.n_support//2)\n",
    "        self.pos_idx[category] += (self.batch_size//2 - self.n_support//2)\n",
    "        \n",
    "        # padding support text dataset\n",
    "        if self.n_support:\n",
    "            neg_support_text = pad_sequence([n for n in neg_support_text], batch_first=True)\n",
    "            pos_support_text = pad_sequence([n for n in pos_support_text], batch_first=True)\n",
    "            neg_support_text, pos_support_text = pad_text(neg_support_text, pos_support_text)\n",
    "        else:\n",
    "            neg_support_text = torch.tensor([[]])\n",
    "            pos_support_text = torch.tensor([[]])\n",
    "            \n",
    "        # padding text dataset\n",
    "        neg_query_text = pad_sequence([n for n in neg_query_text], batch_first=True)\n",
    "        pos_query_text = pad_sequence([p for p in pos_query_text], batch_first=True)\n",
    "        neg_query_text, pos_query_text = pad_text(neg_query_text, pos_query_text)\n",
    "\n",
    "        # concatenating support/query text dataset\n",
    "        support_text = torch.cat([neg_support_text, pos_support_text], dim=0)\n",
    "        query_text = torch.cat([neg_query_text, pos_query_text], dim=0)\n",
    "        support_text, query_text = pad_text(support_text, query_text)\n",
    "\n",
    "        # make final data and label\n",
    "        if self.n_support:\n",
    "            data = torch.cat([support_text, query_text], dim=0)\n",
    "        else:\n",
    "            data = query_text\n",
    "        label = torch.cat([neg_support_label, pos_support_label, neg_query_label, pos_query_label], dim=0)\n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "support = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = AmazonDataLoader(train_dataset, batch_size=64, n_support=support*2)\n",
    "dev_dataloader = AmazonDataLoader(dev_dataset, batch_size=64, n_support=support*2)\n",
    "test_dataloader = AmazonDataLoader(test_dataset, batch_size=64, n_support=support*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 149]) tensor(0.5000)\n",
      "torch.Size([64, 460]) tensor(0.5000)\n",
      "torch.Size([64, 254]) tensor(0.5000)\n",
      "torch.Size([64, 262]) tensor(0.5000)\n",
      "torch.Size([64, 1283]) tensor(0.5000)\n",
      "torch.Size([64, 1658]) tensor(0.5000)\n",
      "torch.Size([64, 613]) tensor(0.5000)\n",
      "torch.Size([64, 359]) tensor(0.5000)\n",
      "torch.Size([64, 530]) tensor(0.5000)\n",
      "torch.Size([64, 602]) tensor(0.5000)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    d, l = train_dataloader.get_batch()\n",
    "    print(d.shape, l.float().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 327]) tensor(0.5000)\n",
      "torch.Size([55, 181]) tensor(0.5818)\n",
      "torch.Size([64, 198]) tensor(0.5000)\n",
      "torch.Size([46, 295]) tensor(0.6957)\n",
      "torch.Size([64, 197]) tensor(0.5000)\n",
      "torch.Size([64, 276]) tensor(0.5000)\n",
      "torch.Size([55, 186]) tensor(0.5818)\n",
      "torch.Size([64, 270]) tensor(0.5000)\n",
      "torch.Size([26, 130]) tensor(0.4615)\n",
      "torch.Size([64, 327]) tensor(0.5000)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    d, l = dev_dataloader.get_batch_test()\n",
    "    print(d.shape, l.float().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 743]) tensor(0.5000)\n",
      "torch.Size([64, 841]) tensor(0.5000)\n",
      "torch.Size([64, 1386]) tensor(0.5000)\n",
      "torch.Size([64, 706]) tensor(0.5000)\n",
      "torch.Size([64, 1026]) tensor(0.5000)\n",
      "torch.Size([64, 1126]) tensor(0.5000)\n",
      "torch.Size([64, 1116]) tensor(0.5000)\n",
      "torch.Size([64, 1333]) tensor(0.5000)\n",
      "torch.Size([64, 568]) tensor(0.5000)\n",
      "torch.Size([64, 570]) tensor(0.5000)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    d, l = test_dataloader.get_batch_test()\n",
    "    print(d.shape, l.float().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class AmazonDataLoader():\n",
    "#     def __init__(self, dataset, amount, batch_size):\n",
    "#         self.amount = amount\n",
    "#         self.dataset = dataset\n",
    "#         self.batch_size = batch_size\n",
    "#         self.categories = list(dataset.dataset.keys())\n",
    "#         self.category_idx = 0\n",
    "#         self.indices_per_category = {\n",
    "#             category: 0 for category in self.categories\n",
    "#         }\n",
    "#         self.n_data_per_category = {\n",
    "#             category: len(dataset.dataset[category]['indice']) for category in self.categories\n",
    "#         }\n",
    "#     def get_batch(self):\n",
    "#         idx = self.category_idx % len(self.categories)\n",
    "#         category = self.categories[idx]\n",
    "#         n_data_per_category = self.n_data_per_category[category]\n",
    "#         start_idx = self.indices_per_category[category] % n_data_per_category\n",
    "#         indice = self.dataset.dataset[category]['indice'][start_idx:start_idx+self.batch_size]\n",
    "#         labels = self.dataset.dataset[category]['label'][start_idx:start_idx+self.batch_size]\n",
    "#         self.indices_per_category[category] += self.batch_size\n",
    "#         self.category_idx += 1\n",
    "        \n",
    "#         if len(indice) != self.batch_size:\n",
    "#             return self.get_batch()\n",
    "        \n",
    "#         indice = pad_sequence(indice, batch_first=True)\n",
    "#         return indice, labels, category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FewShotInduction(C=2,\n",
    "                         S=support,\n",
    "                         vocab_size=len(tokenizer),\n",
    "                         embed_size=300,\n",
    "                         hidden_size=128,\n",
    "                         d_a=64,\n",
    "                         iterations=3,\n",
    "                         outsize=100)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=float(1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = Criterion(way=2, shot=support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(episode):\n",
    "    model.train()\n",
    "    data, target = train_dataloader.get_batch()\n",
    "    data = data.cuda()\n",
    "    target = target.cuda()\n",
    "    optimizer.zero_grad()\n",
    "    predict = model(data)\n",
    "    loss, acc = criterion(predict, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dev(episode):\n",
    "    model.eval()\n",
    "    correct = 0.\n",
    "    count = 0.\n",
    "    for i in range(100):\n",
    "        data, target = dev_dataloader.get_batch_test()\n",
    "        data = data.cuda()\n",
    "        target = target.cuda()\n",
    "        predict = model(data)\n",
    "        _, acc = criterion(predict, target)\n",
    "        amount = len(target) - support * 2\n",
    "        correct += acc * amount\n",
    "        count += amount\n",
    "    acc = correct / count\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    correct = 0.\n",
    "    count = 0.\n",
    "    for i in range(100):\n",
    "        data, target = test_dataloader.get_batch_test()\n",
    "        data = data.cuda()\n",
    "        target = target.cuda()\n",
    "        predict = model(data)\n",
    "        _, acc = criterion(predict, target)\n",
    "        amount = len(target) - support * 2\n",
    "        correct += acc * amount\n",
    "        count += amount\n",
    "        \n",
    "    acc = correct / count\n",
    "    print('Test Acc: {}'.format(acc))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_interval = 100\n",
    "best_acc = -1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 101/9999 [00:24<1:39:28,  1.66it/s, loss=tensor(0.4911, device='cuda:0', grad_fn=<MeanBackward0>)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better acc! Saving model! -> 0.5374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 201/9999 [00:49<1:41:05,  1.62it/s, loss=tensor(0.5000, device='cuda:0', grad_fn=<MeanBackward0>)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better acc! Saving model! -> 0.5421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 500/9999 [02:02<2:03:14,  1.28it/s, loss=tensor(0.4907, device='cuda:0', grad_fn=<MeanBackward0>)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better acc! Saving model! -> 0.5428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 3200/9999 [12:54<1:27:25,  1.30it/s, loss=tensor(0.5259, device='cuda:0', grad_fn=<MeanBackward0>)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better acc! Saving model! -> 0.5548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 3601/9999 [14:31<1:03:33,  1.68it/s, loss=tensor(0.3047, device='cuda:0', grad_fn=<MeanBackward0>)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better acc! Saving model! -> 0.6022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 3701/9999 [14:56<1:05:37,  1.60it/s, loss=tensor(0.4654, device='cuda:0', grad_fn=<MeanBackward0>)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better acc! Saving model! -> 0.6230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 3900/9999 [15:44<1:18:19,  1.30it/s, loss=tensor(0.4810, device='cuda:0', grad_fn=<MeanBackward0>)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better acc! Saving model! -> 0.6518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4000/9999 [16:07<1:18:58,  1.27it/s, loss=tensor(0.2676, device='cuda:0', grad_fn=<MeanBackward0>)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better acc! Saving model! -> 0.6539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 4100/9999 [16:32<1:18:33,  1.25it/s, loss=tensor(0.2664, device='cuda:0', grad_fn=<MeanBackward0>)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better acc! Saving model! -> 0.6652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 4200/9999 [16:56<1:16:40,  1.26it/s, loss=tensor(0.2961, device='cuda:0', grad_fn=<MeanBackward0>)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better acc! Saving model! -> 0.6730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 4300/9999 [17:20<1:14:57,  1.27it/s, loss=tensor(0.1779, device='cuda:0', grad_fn=<MeanBackward0>)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better acc! Saving model! -> 0.6873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 4500/9999 [18:09<1:10:59,  1.29it/s, loss=tensor(0.1996, device='cuda:0', grad_fn=<MeanBackward0>)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better acc! Saving model! -> 0.6883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5001/9999 [20:11<50:16,  1.66it/s, loss=tensor(0.1750, device='cuda:0', grad_fn=<MeanBackward0>)]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better acc! Saving model! -> 0.6964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 5100/9999 [20:35<1:05:25,  1.25it/s, loss=tensor(0.3406, device='cuda:0', grad_fn=<MeanBackward0>)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better acc! Saving model! -> 0.7037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 5900/9999 [23:48<53:08,  1.29it/s, loss=tensor(0.0876, device='cuda:0', grad_fn=<MeanBackward0>)]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better acc! Saving model! -> 0.7123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6000/9999 [24:13<51:30,  1.29it/s, loss=tensor(0.1551, device='cuda:0', grad_fn=<MeanBackward0>)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better acc! Saving model! -> 0.7133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 6200/9999 [25:01<50:09,  1.26it/s, loss=tensor(0.2443, device='cuda:0', grad_fn=<MeanBackward0>)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better acc! Saving model! -> 0.7195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 6501/9999 [26:14<34:55,  1.67it/s, loss=tensor(0.1500, device='cuda:0', grad_fn=<MeanBackward0>)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better acc! Saving model! -> 0.7287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6700/9999 [27:02<41:29,  1.33it/s, loss=tensor(0.1373, device='cuda:0', grad_fn=<MeanBackward0>)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better acc! Saving model! -> 0.7345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 7600/9999 [30:41<32:03,  1.25it/s, loss=tensor(0.2500, device='cuda:0', grad_fn=<MeanBackward0>)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better acc! Saving model! -> 0.7393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 8200/9999 [33:06<23:03,  1.30it/s, loss=tensor(0.0173, device='cuda:0', grad_fn=<MeanBackward0>)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better acc! Saving model! -> 0.7446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 8400/9999 [33:55<21:26,  1.24it/s, loss=tensor(0.2435, device='cuda:0', grad_fn=<MeanBackward0>)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better acc! Saving model! -> 0.7486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9000/9999 [36:20<13:24,  1.24it/s, loss=tensor(0.0522, device='cuda:0', grad_fn=<MeanBackward0>)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better acc! Saving model! -> 0.7496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 9200/9999 [37:09<10:15,  1.30it/s, loss=tensor(0.0444, device='cuda:0', grad_fn=<MeanBackward0>)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better acc! Saving model! -> 0.7497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 9301/9999 [37:33<07:19,  1.59it/s, loss=tensor(0.2773, device='cuda:0', grad_fn=<MeanBackward0>)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better acc! Saving model! -> 0.7528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 9400/9999 [37:57<07:49,  1.28it/s, loss=tensor(0.0272, device='cuda:0', grad_fn=<MeanBackward0>)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better acc! Saving model! -> 0.7531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 9800/9999 [39:33<02:45,  1.20it/s, loss=tensor(0.2823, device='cuda:0', grad_fn=<MeanBackward0>)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better acc! Saving model! -> 0.7546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 9900/9999 [39:57<01:16,  1.30it/s, loss=tensor(0.2743, device='cuda:0', grad_fn=<MeanBackward0>)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better acc! Saving model! -> 0.7551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9999/9999 [40:19<00:00,  4.13it/s, loss=tensor(0.2489, device='cuda:0', grad_fn=<MeanBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "tbar = tqdm(range(1, 10000))\n",
    "for episode in tbar:\n",
    "    \n",
    "    loss = train(episode)\n",
    "    if episode % dev_interval == 0:\n",
    "        acc = dev(episode)\n",
    "        if acc > best_acc:\n",
    "            print('Better acc! Saving model! -> {:.4f}'.format(acc))\n",
    "            best_acc = acc\n",
    "    tbar.set_postfix(loss=loss)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'fewshot_model_{support}.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 jkfirst jkfirst 62M 10월  7 13:11 fewshot_model.bin\r\n",
      "-rw-r--r-- 1 jkfirst jkfirst 62M 10월  7 13:11 fewshot_model_0.bin\r\n",
      "-rw-rw-r-- 1 jkfirst jkfirst 62M 10월  7 14:44 fewshot_model_5.bin\r\n"
     ]
    }
   ],
   "source": [
    "! ls -alh *.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['books', 'dvd', 'electronics', 'kitchen_housewares']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['grocery',\n",
       " 'office_products',\n",
       " 'outdoor_living',\n",
       " 'gourmet_food',\n",
       " 'jewelry_watches']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_dataset.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apparel',\n",
       " 'automotive',\n",
       " 'baby',\n",
       " 'beauty',\n",
       " 'camera_photo',\n",
       " 'cell_phones_service',\n",
       " 'computer_video_games',\n",
       " 'health_personal_care',\n",
       " 'magazines',\n",
       " 'music',\n",
       " 'software',\n",
       " 'sports_outdoors',\n",
       " 'toys_games',\n",
       " 'video']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.6549707651138306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.6550, device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['books', 'dvd', 'electronics', 'kitchen_housewares']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neg = 0\n",
    "n_pos = 0\n",
    "for c in test_dataset.categories:\n",
    "    n_neg += len(test_dataset.dataset[c]['neg']['label'])\n",
    "    n_pos += len(test_dataset.dataset[c]['pos']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1987 7178\n"
     ]
    }
   ],
   "source": [
    "print(n_neg, n_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.modules.loss import _Loss\n",
    "\n",
    "\n",
    "class Criterion_(_Loss):\n",
    "    def __init__(self, way=2, shot=5):\n",
    "        super(Criterion_, self).__init__()\n",
    "        self.amount = way * shot\n",
    "\n",
    "    def forward(self, probs, target, return_pred_label=False):  # (Q,C) (Q)\n",
    "        target = target[self.amount:]\n",
    "        target_onehot = torch.zeros_like(probs)\n",
    "        #print('** sum of probs/target_onehot: {} {}'.format(probs.sum(), target_onehot.sum()))\n",
    "        target_onehot = target_onehot.scatter(1, target.reshape(-1, 1), 1)\n",
    "        loss = torch.mean((probs - target_onehot) ** 2)\n",
    "        pred = torch.argmax(probs, dim=1)\n",
    "        acc = torch.sum(target == pred).float() / target.shape[0]\n",
    "        #print('** acc: {}'.format(acc))\n",
    "\n",
    "        if return_pred_label:\n",
    "            return loss, acc, pred, target\n",
    "        else:\n",
    "            return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_ = Criterion_(way=2, shot=support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_():\n",
    "    model.eval()\n",
    "    correct = 0.\n",
    "    count = 0.\n",
    "    p_list = []\n",
    "    l_list = []\n",
    "    r_list = []\n",
    "    for i in range(100):\n",
    "        data, target = test_dataloader.get_batch_test()\n",
    "        data = data.cuda()\n",
    "        target = target.cuda()\n",
    "        predict = model(data)\n",
    "        _, acc, p, l = criterion_(predict, target, return_pred_label=True)\n",
    "        amount = len(target) - 5 * 2    # 5 = support\n",
    "        correct += acc * amount\n",
    "        count += amount\n",
    "        \n",
    "        r = [1 if np.random.random() < 0.5 else 0 for _ in range(len(l))]\n",
    "        p_list.extend(list(p.cpu().numpy()))\n",
    "        l_list.extend(list(l.cpu().numpy()))\n",
    "        r_list.extend(r)\n",
    "    acc = correct / count\n",
    "    print('Test Acc: {}'.format(acc))\n",
    "    mat = confusion_matrix(l_list, p_list)\n",
    "    print(mat)\n",
    "    \n",
    "    rmat = confusion_matrix(l_list, r_list)\n",
    "    print(rmat)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# support=5\n",
    "Test Acc: 0.7019630074501038\n",
    "[[1707  921]\n",
    " [ 658 2012]]\n",
    "[[1293 1335]\n",
    " [1300 1370]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.6597026586532593\n",
      "[[1217 1408]\n",
      " [ 400 2288]]\n",
      "[[1322 1303]\n",
      " [1343 1345]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.6597, device='cuda:0')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5298"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1707+921+658+2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4960362400906002"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1293+1335)/(1293+1335+1300+1370)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pub",
   "language": "python",
   "name": "env_pub"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
