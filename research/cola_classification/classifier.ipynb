{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1e302da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/nlpyang/PreSumm â†’ summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bfff9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import BertForSequenceClassification, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1039a961",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf8bad27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoLADataset(Dataset):\n",
    "    def __init__(self, path, tokenizer, is_train=True):\n",
    "        if is_train:\n",
    "            filename = os.path.join(path, 'raw/in_domain_train.tsv')\n",
    "        else:\n",
    "            filename = os.path.join(path, 'raw/in_domain_dev.tsv')\n",
    "        df = pd.read_csv(filename, \\\n",
    "                               sep='\\t', \\\n",
    "                               names=['source', 'label', 'judgement', 'text'])\n",
    "        self.input_ids = []\n",
    "        self.token_type_ids = []\n",
    "        self.attention_mask = []\n",
    "        for t in df.text:\n",
    "            inp = tokenizer(t, return_tensors='pt')\n",
    "            self.input_ids.append(inp['input_ids'])\n",
    "            self.token_type_ids.append(inp['token_type_ids'])\n",
    "            self.attention_mask.append(inp['attention_mask'])\n",
    "        self.label = df.label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return [self.input_ids[idx], self.token_type_ids[idx], self.attention_mask[idx], self.label[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6ea735d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CoLADataset('../../data/cola_classification', tokenizer)\n",
    "eval_dataset = CoLADataset('../../data/cola_classification', tokenizer, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ee6b012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8551, 527)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e7835f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    input_ids = [b[0][0] for b in batch]\n",
    "    token_type_ids = [b[1][0] for b in batch]\n",
    "    attention_mask = [b[2][0] for b in batch]\n",
    "    label = torch.tensor([b[3] for b in batch])\n",
    "    input_ids = pad_sequence(input_ids, batch_first=True)\n",
    "    token_type_ids = pad_sequence(token_type_ids, batch_first=True)\n",
    "    attention_mask = pad_sequence(attention_mask, batch_first=True)\n",
    "    return input_ids, token_type_ids, attention_mask, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cf325be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, collate_fn=collate_fn, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f27de5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 26]) torch.Size([16, 26]) torch.Size([16, 26]) torch.Size([16])\n",
      "torch.Size([16, 17]) torch.Size([16, 17]) torch.Size([16, 17]) torch.Size([16])\n",
      "torch.Size([16, 15]) torch.Size([16, 15]) torch.Size([16, 15]) torch.Size([16])\n",
      "torch.Size([16, 17]) torch.Size([16, 17]) torch.Size([16, 17]) torch.Size([16])\n",
      "torch.Size([16, 15]) torch.Size([16, 15]) torch.Size([16, 15]) torch.Size([16])\n",
      "torch.Size([16, 20]) torch.Size([16, 20]) torch.Size([16, 20]) torch.Size([16])\n",
      "torch.Size([16, 20]) torch.Size([16, 20]) torch.Size([16, 20]) torch.Size([16])\n",
      "torch.Size([16, 12]) torch.Size([16, 12]) torch.Size([16, 12]) torch.Size([16])\n",
      "torch.Size([16, 23]) torch.Size([16, 23]) torch.Size([16, 23]) torch.Size([16])\n",
      "torch.Size([16, 32]) torch.Size([16, 32]) torch.Size([16, 32]) torch.Size([16])\n",
      "torch.Size([16, 28]) torch.Size([16, 28]) torch.Size([16, 28]) torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "for i, d in enumerate(train_dataloader):\n",
    "    if i > 10:\n",
    "        break\n",
    "    input_ids, token_type_ids, attention_mask, labels = d\n",
    "    print(input_ids.shape, token_type_ids.shape, attention_mask.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8c1df76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels = 2)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bad1ae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr = 2e-5, eps = 1e-8)\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3271a5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer):\n",
    "    for i, d in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids, token_type_ids, attention_mask, labels = d\n",
    "        out = model(input_ids=input_ids, labels=labels)\n",
    "        loss = out[0]\n",
    "        \n",
    "        #print('before backward: {}'.format(loss))\n",
    "        loss.backward()\n",
    "        print('after backward: {}'.format(loss))\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c517bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after backward: 0.682746946811676\n",
      "after backward: 0.5892165303230286\n",
      "after backward: 0.5971190929412842\n",
      "after backward: 0.5736703276634216\n",
      "after backward: 0.6826539039611816\n",
      "after backward: 0.594929575920105\n",
      "after backward: 0.7404893040657043\n",
      "after backward: 0.6180349588394165\n",
      "after backward: 0.6880731582641602\n",
      "after backward: 0.6873162984848022\n",
      "after backward: 0.7961403727531433\n",
      "after backward: 0.6500728726387024\n",
      "after backward: 0.6167759299278259\n",
      "after backward: 0.5961862802505493\n",
      "after backward: 0.5941612720489502\n",
      "after backward: 0.5366067886352539\n",
      "after backward: 0.7621889114379883\n",
      "after backward: 0.49336758255958557\n",
      "after backward: 0.7208257913589478\n",
      "after backward: 0.5851196646690369\n",
      "after backward: 0.576001763343811\n",
      "after backward: 0.5024921298027039\n",
      "after backward: 0.4966876208782196\n",
      "after backward: 0.6248321533203125\n",
      "after backward: 0.6202273964881897\n",
      "after backward: 0.5783764123916626\n",
      "after backward: 0.6319259405136108\n",
      "after backward: 0.6065897941589355\n",
      "after backward: 0.5712325572967529\n",
      "after backward: 0.499444842338562\n",
      "after backward: 0.6491135358810425\n",
      "after backward: 0.8232524991035461\n",
      "after backward: 0.4298056662082672\n",
      "after backward: 0.9490612149238586\n",
      "after backward: 0.6347330212593079\n",
      "after backward: 0.5097482204437256\n",
      "after backward: 0.5872640609741211\n",
      "after backward: 0.5770260691642761\n",
      "after backward: 0.7269037961959839\n",
      "after backward: 0.576265275478363\n",
      "after backward: 0.5874476432800293\n",
      "after backward: 0.5786694288253784\n",
      "after backward: 0.6544825434684753\n",
      "after backward: 0.7426840662956238\n",
      "after backward: 0.4682637155056\n",
      "after backward: 0.7626645565032959\n",
      "after backward: 0.6674643754959106\n",
      "after backward: 0.567767858505249\n",
      "after backward: 0.5328239798545837\n",
      "after backward: 0.5159144997596741\n",
      "after backward: 0.6188730597496033\n",
      "after backward: 0.7169787287712097\n",
      "after backward: 0.5790467262268066\n",
      "after backward: 0.7583593130111694\n",
      "after backward: 0.5648383498191833\n",
      "after backward: 0.6494704484939575\n",
      "after backward: 0.598476231098175\n",
      "after backward: 0.6350374817848206\n",
      "after backward: 0.8147051334381104\n",
      "after backward: 0.664842963218689\n",
      "after backward: 0.676419198513031\n",
      "after backward: 0.6876432299613953\n",
      "after backward: 0.4657486081123352\n",
      "after backward: 0.7168948650360107\n",
      "after backward: 0.690310537815094\n",
      "after backward: 0.7658973932266235\n",
      "after backward: 0.6533345580101013\n",
      "after backward: 0.5698806643486023\n",
      "after backward: 0.4964073598384857\n",
      "after backward: 0.7465239763259888\n",
      "after backward: 0.5905924439430237\n",
      "after backward: 0.638191282749176\n",
      "after backward: 0.5622916221618652\n",
      "after backward: 0.6838236451148987\n",
      "after backward: 0.6989694237709045\n",
      "after backward: 0.6471481919288635\n",
      "after backward: 0.6199213862419128\n",
      "after backward: 0.547955334186554\n",
      "after backward: 0.5741450190544128\n",
      "after backward: 0.598642110824585\n",
      "after backward: 0.6902190446853638\n",
      "after backward: 0.48627862334251404\n",
      "after backward: 0.5814244747161865\n",
      "after backward: 0.5787933468818665\n",
      "after backward: 0.38311630487442017\n",
      "after backward: 0.6074885129928589\n",
      "after backward: 0.690303385257721\n",
      "after backward: 0.7276449203491211\n",
      "after backward: 0.5588181018829346\n",
      "after backward: 0.5430772304534912\n",
      "after backward: 0.42031872272491455\n",
      "after backward: 0.5196946859359741\n",
      "after backward: 0.6195248961448669\n",
      "after backward: 0.5735746622085571\n",
      "after backward: 0.48660194873809814\n",
      "after backward: 0.49643927812576294\n",
      "after backward: 0.6371968984603882\n",
      "after backward: 0.5610038042068481\n",
      "after backward: 0.511700451374054\n",
      "after backward: 0.5349525809288025\n",
      "after backward: 0.6898064613342285\n",
      "after backward: 0.47754180431365967\n",
      "after backward: 0.4253872334957123\n",
      "after backward: 0.4446209967136383\n",
      "after backward: 0.5067288279533386\n",
      "after backward: 0.5221397876739502\n",
      "after backward: 0.5989532470703125\n",
      "after backward: 0.4381002187728882\n",
      "after backward: 0.760977029800415\n",
      "after backward: 0.6277795433998108\n",
      "after backward: 0.4864622950553894\n",
      "after backward: 0.5030831098556519\n",
      "after backward: 0.5452099442481995\n",
      "after backward: 0.5998038053512573\n",
      "after backward: 0.3525264859199524\n",
      "after backward: 0.7998269200325012\n",
      "after backward: 0.515139639377594\n",
      "after backward: 0.6878427863121033\n",
      "after backward: 0.5726480484008789\n",
      "after backward: 0.4471154808998108\n",
      "after backward: 0.4540867507457733\n",
      "after backward: 0.4874684512615204\n",
      "after backward: 0.6557984352111816\n",
      "after backward: 0.5346335768699646\n",
      "after backward: 0.38190996646881104\n",
      "after backward: 0.6049628853797913\n",
      "after backward: 0.5222644209861755\n",
      "after backward: 0.385786771774292\n",
      "after backward: 0.47911036014556885\n",
      "after backward: 0.6148924827575684\n",
      "after backward: 0.4053865671157837\n",
      "after backward: 0.45897072553634644\n",
      "after backward: 0.5817995667457581\n",
      "after backward: 0.5647749304771423\n",
      "after backward: 0.4015354514122009\n",
      "after backward: 0.41790273785591125\n",
      "after backward: 0.6073278188705444\n",
      "after backward: 0.9528387784957886\n",
      "after backward: 0.3755575120449066\n",
      "after backward: 0.4559714198112488\n",
      "after backward: 0.4339124262332916\n",
      "after backward: 0.4469333291053772\n",
      "after backward: 0.3868485391139984\n",
      "after backward: 0.47574281692504883\n",
      "after backward: 0.7303673028945923\n",
      "after backward: 0.6191250681877136\n",
      "after backward: 0.5540213584899902\n",
      "after backward: 0.49142205715179443\n",
      "after backward: 0.46608442068099976\n",
      "after backward: 0.6214885711669922\n",
      "after backward: 0.6072944402694702\n",
      "after backward: 0.6045997738838196\n",
      "after backward: 0.4908253252506256\n",
      "after backward: 0.46054545044898987\n",
      "after backward: 0.5610542297363281\n",
      "after backward: 0.6272238492965698\n",
      "after backward: 0.4513046145439148\n",
      "after backward: 0.5817345380783081\n",
      "after backward: 0.6539252996444702\n",
      "after backward: 0.47096237540245056\n",
      "after backward: 0.4238143265247345\n",
      "after backward: 0.572481095790863\n",
      "after backward: 0.5366230010986328\n",
      "after backward: 0.8753246665000916\n",
      "after backward: 0.5618780851364136\n",
      "after backward: 0.3526880443096161\n",
      "after backward: 0.471566379070282\n",
      "after backward: 0.3824133276939392\n",
      "after backward: 0.366428017616272\n",
      "after backward: 0.513361930847168\n",
      "after backward: 0.35833531618118286\n",
      "after backward: 0.4967712163925171\n",
      "after backward: 0.4816073775291443\n",
      "after backward: 0.6492175459861755\n",
      "after backward: 0.6102811098098755\n",
      "after backward: 0.37351325154304504\n",
      "after backward: 0.3994844853878021\n",
      "after backward: 0.48966550827026367\n",
      "after backward: 0.535071074962616\n",
      "after backward: 0.39841169118881226\n",
      "after backward: 0.6802266240119934\n",
      "after backward: 0.4142877459526062\n",
      "after backward: 0.46852588653564453\n",
      "after backward: 0.2662215232849121\n",
      "after backward: 0.5017324686050415\n",
      "after backward: 0.26800793409347534\n",
      "after backward: 0.7379123568534851\n",
      "after backward: 0.2984107434749603\n",
      "after backward: 0.6279840469360352\n",
      "after backward: 0.6617929935455322\n",
      "after backward: 0.6323559880256653\n",
      "after backward: 0.38822421431541443\n",
      "after backward: 0.4836958050727844\n",
      "after backward: 0.6561450362205505\n",
      "after backward: 0.47356051206588745\n",
      "after backward: 0.5687845349311829\n",
      "after backward: 0.516350507736206\n",
      "after backward: 0.4583177864551544\n",
      "after backward: 0.6006506085395813\n",
      "after backward: 0.6730008125305176\n",
      "after backward: 0.620959997177124\n",
      "after backward: 0.3740304410457611\n",
      "after backward: 0.2489137053489685\n",
      "after backward: 0.38742461800575256\n",
      "after backward: 0.42283758521080017\n",
      "after backward: 0.504910409450531\n",
      "after backward: 0.6407154202461243\n",
      "after backward: 0.5270020365715027\n",
      "after backward: 0.33198127150535583\n",
      "after backward: 0.3468102812767029\n",
      "after backward: 0.543213963508606\n",
      "after backward: 0.6022870540618896\n",
      "after backward: 0.5609371066093445\n",
      "after backward: 0.29717689752578735\n",
      "after backward: 0.5333899855613708\n",
      "after backward: 0.3741592764854431\n",
      "after backward: 0.6097245812416077\n",
      "after backward: 0.48605841398239136\n",
      "after backward: 0.49256935715675354\n",
      "after backward: 0.5643553137779236\n",
      "after backward: 0.6600574851036072\n",
      "after backward: 0.5276974439620972\n",
      "after backward: 0.3849819302558899\n",
      "after backward: 0.4104002118110657\n",
      "after backward: 0.41828638315200806\n",
      "after backward: 0.2772414982318878\n",
      "after backward: 0.6650725603103638\n",
      "after backward: 0.721167802810669\n",
      "after backward: 0.5235763192176819\n",
      "after backward: 0.4582138955593109\n",
      "after backward: 0.6189944744110107\n",
      "after backward: 0.6785285472869873\n",
      "after backward: 0.5025638937950134\n",
      "after backward: 0.6394245028495789\n",
      "after backward: 0.4534783959388733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after backward: 0.5549787878990173\n",
      "after backward: 0.4486159086227417\n",
      "after backward: 0.602379560470581\n",
      "after backward: 0.36974450945854187\n",
      "after backward: 0.4278520941734314\n",
      "after backward: 0.3878175914287567\n",
      "after backward: 0.48019644618034363\n",
      "after backward: 0.5778515338897705\n",
      "after backward: 0.36958763003349304\n",
      "after backward: 0.6079637408256531\n",
      "after backward: 0.5354700088500977\n",
      "after backward: 0.5132678151130676\n",
      "after backward: 0.4545446038246155\n",
      "after backward: 0.5322014093399048\n",
      "after backward: 0.5130562782287598\n",
      "after backward: 0.6457064747810364\n",
      "after backward: 0.4782536029815674\n",
      "after backward: 0.484110027551651\n",
      "after backward: 0.3198695182800293\n",
      "after backward: 0.4555729627609253\n",
      "after backward: 0.4262423515319824\n",
      "after backward: 0.4781089127063751\n",
      "after backward: 0.3976157009601593\n",
      "after backward: 0.36007121205329895\n",
      "after backward: 0.30758973956108093\n",
      "after backward: 0.45400115847587585\n",
      "after backward: 0.34655269980430603\n",
      "after backward: 0.8499913811683655\n",
      "after backward: 0.6552799344062805\n",
      "after backward: 0.31096458435058594\n",
      "after backward: 0.4531770348548889\n",
      "after backward: 0.4150311350822449\n",
      "after backward: 0.433782696723938\n",
      "after backward: 0.3490367531776428\n",
      "after backward: 0.6500065922737122\n",
      "after backward: 0.5434699058532715\n",
      "after backward: 0.6208887696266174\n",
      "after backward: 0.309964120388031\n",
      "after backward: 0.44849157333374023\n",
      "after backward: 0.3486694395542145\n",
      "after backward: 0.4193751811981201\n",
      "after backward: 0.6421923041343689\n",
      "after backward: 0.2412135750055313\n",
      "after backward: 0.3034604489803314\n",
      "after backward: 0.4656131863594055\n",
      "after backward: 0.33730772137641907\n",
      "after backward: 0.3935595154762268\n",
      "after backward: 0.5825323462486267\n",
      "after backward: 0.5593295693397522\n",
      "after backward: 0.4825754463672638\n",
      "after backward: 0.5103847980499268\n",
      "after backward: 0.4891762435436249\n",
      "after backward: 0.3077913522720337\n",
      "after backward: 0.22605788707733154\n",
      "after backward: 0.453914612531662\n",
      "after backward: 0.4289052486419678\n",
      "after backward: 0.31330767273902893\n",
      "after backward: 0.3196994960308075\n",
      "after backward: 0.6525610685348511\n",
      "after backward: 0.3888542950153351\n",
      "after backward: 0.3753441572189331\n",
      "after backward: 0.4663963317871094\n",
      "after backward: 0.31707414984703064\n",
      "after backward: 0.4780913293361664\n",
      "after backward: 0.5354437828063965\n",
      "after backward: 0.3980640172958374\n",
      "after backward: 0.37084144353866577\n",
      "after backward: 0.6231021285057068\n",
      "after backward: 0.22003334760665894\n",
      "after backward: 0.23657827079296112\n",
      "after backward: 0.593914806842804\n",
      "after backward: 0.32652759552001953\n",
      "after backward: 0.5136159062385559\n",
      "after backward: 0.6819788217544556\n",
      "after backward: 0.5689119100570679\n",
      "after backward: 0.5342684984207153\n",
      "after backward: 0.47564566135406494\n",
      "after backward: 0.567238986492157\n",
      "after backward: 0.5815181136131287\n",
      "after backward: 0.5255618095397949\n",
      "after backward: 0.3676601052284241\n",
      "after backward: 0.26693961024284363\n",
      "after backward: 0.3751205503940582\n",
      "after backward: 0.6058570146560669\n",
      "after backward: 0.41597431898117065\n",
      "after backward: 0.4699718952178955\n",
      "after backward: 0.6079244017601013\n",
      "after backward: 0.47729575634002686\n",
      "after backward: 0.3783968687057495\n",
      "after backward: 0.570047914981842\n",
      "after backward: 0.40258410573005676\n",
      "after backward: 0.5807927846908569\n",
      "after backward: 0.6591096520423889\n",
      "after backward: 0.4472222924232483\n",
      "after backward: 0.6337380409240723\n",
      "after backward: 0.525367259979248\n",
      "after backward: 0.38549715280532837\n",
      "after backward: 0.4126277267932892\n",
      "after backward: 0.40003857016563416\n",
      "after backward: 0.19649586081504822\n",
      "after backward: 0.3216296136379242\n",
      "after backward: 0.4890313446521759\n",
      "after backward: 0.3720977306365967\n",
      "after backward: 0.5009498596191406\n",
      "after backward: 0.3833528459072113\n",
      "after backward: 0.47272413969039917\n",
      "after backward: 0.3976610004901886\n",
      "after backward: 0.4269387423992157\n",
      "after backward: 0.3228859007358551\n",
      "after backward: 0.5333391427993774\n",
      "after backward: 0.2413778454065323\n",
      "after backward: 0.39327242970466614\n",
      "after backward: 0.3198499381542206\n",
      "after backward: 0.7784022092819214\n",
      "after backward: 0.6133521795272827\n",
      "after backward: 0.3607875108718872\n",
      "after backward: 0.345760315656662\n",
      "after backward: 0.5795847177505493\n",
      "after backward: 0.4482285678386688\n",
      "after backward: 0.3775263726711273\n",
      "after backward: 0.5016067028045654\n",
      "after backward: 0.5047364234924316\n",
      "after backward: 0.552634596824646\n",
      "after backward: 0.36399537324905396\n",
      "after backward: 0.45938485860824585\n",
      "after backward: 0.4731018543243408\n",
      "after backward: 0.3810672163963318\n",
      "after backward: 0.5604566931724548\n",
      "after backward: 0.30533626675605774\n",
      "after backward: 0.29867830872535706\n",
      "after backward: 0.4947319030761719\n",
      "after backward: 0.4024602174758911\n",
      "after backward: 0.32456159591674805\n",
      "after backward: 0.617991030216217\n",
      "after backward: 0.42031750082969666\n",
      "after backward: 0.21452701091766357\n",
      "after backward: 0.3556954264640808\n",
      "after backward: 0.4165881872177124\n",
      "after backward: 0.16598549485206604\n",
      "after backward: 0.3117077648639679\n",
      "after backward: 0.9697110652923584\n",
      "after backward: 0.7090843915939331\n",
      "after backward: 0.22485187649726868\n",
      "after backward: 0.6444834470748901\n",
      "after backward: 0.4847643971443176\n",
      "after backward: 0.5798418521881104\n",
      "after backward: 0.3428065776824951\n",
      "after backward: 0.25235167145729065\n",
      "after backward: 0.20997217297554016\n",
      "after backward: 0.3633672893047333\n",
      "after backward: 0.8016147613525391\n",
      "after backward: 0.26311689615249634\n",
      "after backward: 0.21956807374954224\n",
      "after backward: 0.22227412462234497\n",
      "after backward: 0.4364657402038574\n",
      "after backward: 0.34813961386680603\n",
      "after backward: 0.4900778532028198\n",
      "after backward: 0.2760019600391388\n",
      "after backward: 0.47155460715293884\n",
      "after backward: 0.4899067282676697\n",
      "after backward: 0.43495965003967285\n",
      "after backward: 0.488878458738327\n",
      "after backward: 0.4961130917072296\n",
      "after backward: 0.4981730580329895\n",
      "after backward: 0.3168635070323944\n",
      "after backward: 0.3154336214065552\n",
      "after backward: 0.315889447927475\n",
      "after backward: 0.6139004826545715\n",
      "after backward: 0.2079540491104126\n",
      "after backward: 0.6606970429420471\n",
      "after backward: 0.44152358174324036\n",
      "after backward: 0.31883394718170166\n",
      "after backward: 0.35835397243499756\n",
      "after backward: 0.29693368077278137\n",
      "after backward: 0.16245931386947632\n",
      "after backward: 0.3417426347732544\n",
      "after backward: 0.32846158742904663\n",
      "after backward: 0.3986406624317169\n",
      "after backward: 0.4959302246570587\n",
      "after backward: 0.1779506355524063\n",
      "after backward: 0.5357021689414978\n",
      "after backward: 0.5376831293106079\n",
      "after backward: 0.8275713920593262\n",
      "after backward: 0.7008620500564575\n",
      "after backward: 0.3299690783023834\n",
      "after backward: 0.357629656791687\n",
      "after backward: 0.5308696031570435\n",
      "after backward: 0.5582281947135925\n",
      "after backward: 0.3706818222999573\n",
      "after backward: 0.8121123313903809\n",
      "after backward: 0.48324665427207947\n",
      "after backward: 0.2651403546333313\n",
      "after backward: 0.3348177671432495\n",
      "after backward: 0.3714914619922638\n",
      "after backward: 0.4188478887081146\n",
      "after backward: 0.4299790561199188\n",
      "after backward: 0.6727207899093628\n",
      "after backward: 0.5060405135154724\n",
      "after backward: 0.2716236114501953\n",
      "after backward: 0.42604342103004456\n",
      "after backward: 0.1121741458773613\n",
      "after backward: 0.38619059324264526\n",
      "after backward: 0.3830186426639557\n",
      "after backward: 0.5676690936088562\n",
      "after backward: 0.38898661732673645\n",
      "after backward: 0.6066249012947083\n",
      "after backward: 0.423545241355896\n",
      "after backward: 0.6811968684196472\n",
      "after backward: 0.621982753276825\n",
      "after backward: 0.417520135641098\n",
      "after backward: 0.3999258279800415\n",
      "after backward: 0.3129325211048126\n",
      "after backward: 0.41957637667655945\n",
      "after backward: 0.5107731223106384\n",
      "after backward: 0.843714714050293\n",
      "after backward: 0.22567686438560486\n",
      "after backward: 0.2812391519546509\n",
      "after backward: 0.46967053413391113\n",
      "after backward: 0.2936549186706543\n",
      "after backward: 0.43991050124168396\n",
      "after backward: 0.3161892890930176\n",
      "after backward: 0.6522194743156433\n",
      "after backward: 0.3965339660644531\n",
      "after backward: 0.25331300497055054\n",
      "after backward: 0.3018183410167694\n",
      "after backward: 0.3303476870059967\n",
      "after backward: 0.4931489825248718\n",
      "after backward: 0.7312765121459961\n",
      "after backward: 0.5207559466362\n",
      "after backward: 0.2461087554693222\n",
      "after backward: 0.3939655125141144\n",
      "after backward: 0.715922474861145\n",
      "after backward: 0.5947844982147217\n",
      "after backward: 0.6239405274391174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after backward: 0.25974270701408386\n",
      "after backward: 0.33952850103378296\n",
      "after backward: 0.23443208634853363\n",
      "after backward: 0.5619715452194214\n",
      "after backward: 0.41095876693725586\n",
      "after backward: 0.3504435420036316\n",
      "after backward: 0.19272997975349426\n",
      "after backward: 0.5429831147193909\n",
      "after backward: 0.416250079870224\n",
      "after backward: 0.44957268238067627\n",
      "after backward: 0.32560616731643677\n",
      "after backward: 0.28038734197616577\n",
      "after backward: 0.5670682191848755\n",
      "after backward: 0.37773725390434265\n",
      "after backward: 0.433677077293396\n",
      "after backward: 0.23663640022277832\n",
      "after backward: 0.3985004127025604\n",
      "after backward: 0.6404274702072144\n",
      "after backward: 0.42583486437797546\n",
      "after backward: 0.4338298439979553\n",
      "after backward: 0.3775867223739624\n",
      "after backward: 0.9495734572410583\n",
      "after backward: 0.7629899382591248\n",
      "after backward: 0.2331821471452713\n",
      "after backward: 0.37243711948394775\n",
      "after backward: 0.2740698754787445\n",
      "after backward: 0.5311015844345093\n",
      "after backward: 0.30894342064857483\n",
      "after backward: 0.5181388258934021\n",
      "after backward: 0.4127485454082489\n",
      "after backward: 0.44544678926467896\n",
      "after backward: 0.21882249414920807\n",
      "after backward: 0.42719709873199463\n",
      "after backward: 0.5223252177238464\n",
      "after backward: 0.23072616755962372\n",
      "after backward: 0.26683029532432556\n",
      "after backward: 0.41215041279792786\n",
      "after backward: 0.35573744773864746\n",
      "after backward: 0.6432524919509888\n",
      "after backward: 0.4883649945259094\n",
      "after backward: 0.33005082607269287\n",
      "after backward: 0.23329785466194153\n",
      "after backward: 0.4984135031700134\n",
      "after backward: 0.11495309323072433\n",
      "after backward: 0.556715190410614\n",
      "after backward: 0.1825529783964157\n",
      "after backward: 0.20929667353630066\n",
      "after backward: 0.8966612219810486\n",
      "after backward: 0.4060552716255188\n",
      "after backward: 0.24209345877170563\n",
      "after backward: 0.39201557636260986\n",
      "after backward: 0.3117040693759918\n",
      "after backward: 0.3847287893295288\n",
      "after backward: 0.153256356716156\n",
      "after backward: 0.30422505736351013\n",
      "after backward: 0.4116481840610504\n",
      "after backward: 0.26642516255378723\n",
      "after backward: 0.25019732117652893\n",
      "after backward: 0.5684990882873535\n",
      "after backward: 0.4310694634914398\n",
      "after backward: 0.6788647770881653\n",
      "after backward: 0.3301813006401062\n",
      "after backward: 0.36430492997169495\n",
      "after backward: 0.4436827600002289\n",
      "after backward: 0.5058228969573975\n",
      "after backward: 0.5666875243186951\n"
     ]
    }
   ],
   "source": [
    "train(model, train_dataloader, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66f8673c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after backward: 0.09486492723226547\n",
      "after backward: 0.24622975289821625\n",
      "after backward: 0.4799994230270386\n",
      "after backward: 0.27298837900161743\n",
      "after backward: 0.08829061686992645\n",
      "after backward: 0.6410375237464905\n",
      "after backward: 0.08769513666629791\n",
      "after backward: 0.10987889021635056\n",
      "after backward: 0.13490232825279236\n",
      "after backward: 0.42762675881385803\n",
      "after backward: 0.3240242302417755\n",
      "after backward: 0.1917620301246643\n",
      "after backward: 0.08079755306243896\n",
      "after backward: 0.44968703389167786\n",
      "after backward: 0.2532300055027008\n",
      "after backward: 0.5644389390945435\n",
      "after backward: 0.24666732549667358\n",
      "after backward: 0.1352958232164383\n",
      "after backward: 0.12333741784095764\n",
      "after backward: 0.10586340725421906\n",
      "after backward: 0.4008282423019409\n",
      "after backward: 0.40094703435897827\n",
      "after backward: 0.39249175786972046\n",
      "after backward: 0.10237585753202438\n",
      "after backward: 0.1559070497751236\n",
      "after backward: 0.2538176476955414\n",
      "after backward: 0.23042088747024536\n",
      "after backward: 0.4617820978164673\n",
      "after backward: 0.15163320302963257\n",
      "after backward: 0.4803200662136078\n",
      "after backward: 0.28519928455352783\n",
      "after backward: 0.09358450770378113\n",
      "after backward: 0.15812601149082184\n",
      "after backward: 0.13845454156398773\n",
      "after backward: 0.11481103301048279\n",
      "after backward: 0.21965208649635315\n",
      "after backward: 0.16045469045639038\n",
      "after backward: 0.41189759969711304\n",
      "after backward: 0.06275670230388641\n",
      "after backward: 0.21950775384902954\n",
      "after backward: 0.34058114886283875\n",
      "after backward: 0.3596159517765045\n",
      "after backward: 0.3166952133178711\n",
      "after backward: 0.141448974609375\n",
      "after backward: 0.22961173951625824\n",
      "after backward: 0.6735755801200867\n",
      "after backward: 0.40616708993911743\n",
      "after backward: 0.1126675233244896\n",
      "after backward: 0.11226377636194229\n",
      "after backward: 0.09134916216135025\n",
      "after backward: 0.2501170337200165\n",
      "after backward: 0.17469963431358337\n",
      "after backward: 0.07838290929794312\n",
      "after backward: 0.5116430521011353\n",
      "after backward: 0.21851640939712524\n",
      "after backward: 0.11498218029737473\n",
      "after backward: 0.13331298530101776\n",
      "after backward: 0.394227534532547\n",
      "after backward: 0.2527381181716919\n",
      "after backward: 0.10276177525520325\n",
      "after backward: 0.128416508436203\n",
      "after backward: 0.04671221226453781\n",
      "after backward: 0.44195058941841125\n",
      "after backward: 0.3315270245075226\n",
      "after backward: 0.8528056740760803\n",
      "after backward: 0.23340265452861786\n",
      "after backward: 0.22369974851608276\n",
      "after backward: 0.21781709790229797\n",
      "after backward: 0.7368284463882446\n",
      "after backward: 0.17003585398197174\n",
      "after backward: 0.16167916357517242\n",
      "after backward: 0.1677880585193634\n",
      "after backward: 0.2434110790491104\n",
      "after backward: 0.12112616002559662\n",
      "after backward: 0.07420174032449722\n",
      "after backward: 0.4309447407722473\n",
      "after backward: 0.11723758280277252\n",
      "after backward: 0.22747963666915894\n",
      "after backward: 0.25354477763175964\n",
      "after backward: 0.27753740549087524\n",
      "after backward: 0.1661427617073059\n",
      "after backward: 0.30022433400154114\n",
      "after backward: 0.15141044557094574\n",
      "after backward: 0.45223405957221985\n",
      "after backward: 0.0712263360619545\n",
      "after backward: 0.40006595849990845\n",
      "after backward: 0.10892771929502487\n",
      "after backward: 0.04605512320995331\n",
      "after backward: 0.2274884730577469\n",
      "after backward: 0.16871163249015808\n",
      "after backward: 0.10549582540988922\n",
      "after backward: 0.18787196278572083\n",
      "after backward: 0.284591943025589\n",
      "after backward: 0.13166795670986176\n",
      "after backward: 0.24940404295921326\n",
      "after backward: 0.6301811337471008\n",
      "after backward: 0.12690983712673187\n",
      "after backward: 0.06386750191450119\n",
      "after backward: 0.501339852809906\n",
      "after backward: 0.29401132464408875\n",
      "after backward: 0.5083196759223938\n",
      "after backward: 0.1958761215209961\n",
      "after backward: 0.19479823112487793\n",
      "after backward: 0.27008453011512756\n",
      "after backward: 0.44494080543518066\n",
      "after backward: 0.13416676223278046\n",
      "after backward: 0.181831493973732\n",
      "after backward: 0.12449874728918076\n",
      "after backward: 0.6672517657279968\n",
      "after backward: 0.3612463176250458\n",
      "after backward: 0.5086150765419006\n",
      "after backward: 0.5447491407394409\n",
      "after backward: 0.46397778391838074\n",
      "after backward: 0.2627336084842682\n",
      "after backward: 0.2864623963832855\n",
      "after backward: 0.11514431238174438\n",
      "after backward: 0.2137312889099121\n",
      "after backward: 0.23562106490135193\n",
      "after backward: 0.4035147428512573\n",
      "after backward: 0.32047727704048157\n",
      "after backward: 0.2517017424106598\n",
      "after backward: 0.5049195289611816\n",
      "after backward: 0.22300387918949127\n",
      "after backward: 0.5773377418518066\n",
      "after backward: 0.22989407181739807\n",
      "after backward: 0.20822158455848694\n",
      "after backward: 0.20653870701789856\n",
      "after backward: 0.1671019196510315\n",
      "after backward: 0.5835907459259033\n",
      "after backward: 0.27538394927978516\n",
      "after backward: 0.41727545857429504\n",
      "after backward: 0.12269663065671921\n",
      "after backward: 0.2513837516307831\n",
      "after backward: 0.16113953292369843\n",
      "after backward: 0.38578617572784424\n",
      "after backward: 0.48250946402549744\n",
      "after backward: 0.22489356994628906\n",
      "after backward: 0.26813745498657227\n",
      "after backward: 0.26678377389907837\n",
      "after backward: 0.18920961022377014\n",
      "after backward: 0.6232147812843323\n",
      "after backward: 0.11287660151720047\n",
      "after backward: 0.41002270579338074\n",
      "after backward: 0.5688279867172241\n",
      "after backward: 0.41272974014282227\n",
      "after backward: 0.13930588960647583\n",
      "after backward: 0.22927823662757874\n",
      "after backward: 0.28906136751174927\n",
      "after backward: 0.1505388766527176\n",
      "after backward: 0.5089475512504578\n",
      "after backward: 0.14875848591327667\n",
      "after backward: 0.310678631067276\n",
      "after backward: 0.19797489047050476\n",
      "after backward: 0.4692372679710388\n",
      "after backward: 0.10325727611780167\n",
      "after backward: 0.1514008790254593\n",
      "after backward: 0.33277276158332825\n",
      "after backward: 0.2944782078266144\n",
      "after backward: 0.40146881341934204\n",
      "after backward: 0.2447245568037033\n",
      "after backward: 0.33696165680885315\n",
      "after backward: 0.41672027111053467\n",
      "after backward: 0.2686499357223511\n",
      "after backward: 0.3048103451728821\n",
      "after backward: 0.24528177082538605\n",
      "after backward: 0.39328885078430176\n",
      "after backward: 0.2590954899787903\n",
      "after backward: 0.25334447622299194\n",
      "after backward: 0.2579052150249481\n",
      "after backward: 0.06709344685077667\n",
      "after backward: 0.2867580056190491\n",
      "after backward: 0.19004206359386444\n",
      "after backward: 0.2550120949745178\n",
      "after backward: 0.50355464220047\n",
      "after backward: 0.1522095650434494\n",
      "after backward: 0.3231959342956543\n",
      "after backward: 0.22158382833003998\n",
      "after backward: 0.18856097757816315\n",
      "after backward: 0.244588240981102\n",
      "after backward: 0.5127004981040955\n",
      "after backward: 0.26448285579681396\n",
      "after backward: 0.3937821090221405\n",
      "after backward: 0.20490382611751556\n",
      "after backward: 0.16215991973876953\n",
      "after backward: 0.18354907631874084\n",
      "after backward: 0.843480110168457\n",
      "after backward: 0.27550122141838074\n",
      "after backward: 0.2637454867362976\n",
      "after backward: 0.3258725702762604\n",
      "after backward: 0.2835308313369751\n",
      "after backward: 0.18433736264705658\n",
      "after backward: 0.3072492182254791\n",
      "after backward: 0.1129111796617508\n",
      "after backward: 0.3061407208442688\n",
      "after backward: 0.30745917558670044\n",
      "after backward: 0.23505833745002747\n",
      "after backward: 0.3228693902492523\n",
      "after backward: 0.31159162521362305\n",
      "after backward: 0.16883952915668488\n",
      "after backward: 0.11888472735881805\n",
      "after backward: 0.15386070311069489\n",
      "after backward: 0.2562427222728729\n",
      "after backward: 0.18634293973445892\n",
      "after backward: 0.11971647292375565\n",
      "after backward: 0.21166163682937622\n",
      "after backward: 0.2039671391248703\n",
      "after backward: 0.30838605761528015\n",
      "after backward: 0.11051570624113083\n",
      "after backward: 0.08238159865140915\n",
      "after backward: 0.30585163831710815\n",
      "after backward: 0.46411949396133423\n",
      "after backward: 0.38237354159355164\n",
      "after backward: 0.6719678640365601\n",
      "after backward: 0.23445633053779602\n",
      "after backward: 0.16241469979286194\n",
      "after backward: 0.3054507076740265\n",
      "after backward: 0.20185181498527527\n",
      "after backward: 0.31393545866012573\n",
      "after backward: 0.19711807370185852\n",
      "after backward: 0.15692122280597687\n",
      "after backward: 0.20588093996047974\n",
      "after backward: 0.37580397725105286\n",
      "after backward: 0.6566710472106934\n",
      "after backward: 0.34254133701324463\n",
      "after backward: 0.23345288634300232\n",
      "after backward: 0.12378307431936264\n",
      "after backward: 0.16923415660858154\n",
      "after backward: 0.27430033683776855\n",
      "after backward: 0.20848430693149567\n",
      "after backward: 0.17377884685993195\n",
      "after backward: 0.3397672176361084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after backward: 0.23587512969970703\n",
      "after backward: 0.03916380926966667\n",
      "after backward: 0.2509854733943939\n",
      "after backward: 0.06710845232009888\n",
      "after backward: 0.29833483695983887\n",
      "after backward: 0.47011780738830566\n",
      "after backward: 0.3735921084880829\n",
      "after backward: 0.5312666893005371\n",
      "after backward: 0.06500791758298874\n",
      "after backward: 0.09102996438741684\n",
      "after backward: 0.30447256565093994\n",
      "after backward: 0.0809883326292038\n",
      "after backward: 0.3997194766998291\n",
      "after backward: 0.3662208020687103\n",
      "after backward: 0.37098807096481323\n",
      "after backward: 0.22690531611442566\n",
      "after backward: 0.13482500612735748\n",
      "after backward: 0.39417678117752075\n",
      "after backward: 0.21313311159610748\n",
      "after backward: 0.24930445849895477\n",
      "after backward: 0.12667474150657654\n",
      "after backward: 0.38752150535583496\n",
      "after backward: 0.2998619079589844\n",
      "after backward: 0.12131449580192566\n",
      "after backward: 0.4092526435852051\n",
      "after backward: 0.12759043276309967\n",
      "after backward: 0.16821175813674927\n",
      "after backward: 0.1995803713798523\n",
      "after backward: 0.3951586186885834\n",
      "after backward: 0.11368812620639801\n",
      "after backward: 0.2317553013563156\n",
      "after backward: 0.490766316652298\n",
      "after backward: 0.1594020277261734\n",
      "after backward: 0.1802596151828766\n",
      "after backward: 0.3647414445877075\n",
      "after backward: 0.6879673600196838\n",
      "after backward: 0.24325907230377197\n",
      "after backward: 0.5513061285018921\n",
      "after backward: 0.14625224471092224\n",
      "after backward: 0.23517118394374847\n",
      "after backward: 0.277973473072052\n",
      "after backward: 0.20301203429698944\n",
      "after backward: 0.15428784489631653\n",
      "after backward: 0.1896626353263855\n",
      "after backward: 0.4570751190185547\n",
      "after backward: 0.16831570863723755\n",
      "after backward: 0.44120466709136963\n",
      "after backward: 0.31226685643196106\n",
      "after backward: 0.42592859268188477\n",
      "after backward: 0.3382872939109802\n",
      "after backward: 0.2503755986690521\n",
      "after backward: 0.1550450623035431\n",
      "after backward: 0.27492836117744446\n",
      "after backward: 0.3969714045524597\n",
      "after backward: 0.20832575857639313\n",
      "after backward: 0.4892418384552002\n",
      "after backward: 0.3697417676448822\n",
      "after backward: 0.23462413251399994\n",
      "after backward: 0.4720240831375122\n",
      "after backward: 0.32741978764533997\n",
      "after backward: 0.7839030623435974\n",
      "after backward: 0.20026645064353943\n",
      "after backward: 0.2656462490558624\n",
      "after backward: 0.368338018655777\n",
      "after backward: 0.24211673438549042\n",
      "after backward: 0.21450911462306976\n",
      "after backward: 0.11390416324138641\n",
      "after backward: 0.34804242849349976\n",
      "after backward: 0.30794286727905273\n",
      "after backward: 0.2780226171016693\n",
      "after backward: 0.34867867827415466\n",
      "after backward: 0.3237512707710266\n",
      "after backward: 0.23486950993537903\n",
      "after backward: 0.3715224266052246\n",
      "after backward: 0.18181529641151428\n",
      "after backward: 0.2783046364784241\n",
      "after backward: 0.25482505559921265\n",
      "after backward: 0.2054673582315445\n",
      "after backward: 0.31961312890052795\n",
      "after backward: 0.42068204283714294\n",
      "after backward: 0.21479582786560059\n",
      "after backward: 0.2972784638404846\n",
      "after backward: 0.6505471467971802\n",
      "after backward: 0.290063738822937\n",
      "after backward: 0.3023538291454315\n",
      "after backward: 0.49642860889434814\n",
      "after backward: 0.2286231517791748\n",
      "after backward: 0.5132959485054016\n",
      "after backward: 0.17596542835235596\n",
      "after backward: 0.4931837022304535\n",
      "after backward: 0.19420388340950012\n",
      "after backward: 0.17961832880973816\n",
      "after backward: 0.09530484676361084\n",
      "after backward: 0.6901172399520874\n",
      "after backward: 0.15998658537864685\n",
      "after backward: 0.1505713313817978\n",
      "after backward: 0.2412196695804596\n",
      "after backward: 0.11869391798973083\n",
      "after backward: 0.1323552131652832\n",
      "after backward: 0.4746558666229248\n",
      "after backward: 0.20111694931983948\n",
      "after backward: 0.11777088791131973\n",
      "after backward: 0.13980482518672943\n",
      "after backward: 0.26998987793922424\n",
      "after backward: 0.21042084693908691\n",
      "after backward: 0.245262011885643\n",
      "after backward: 0.1065666452050209\n",
      "after backward: 0.08117862045764923\n",
      "after backward: 0.384351909160614\n",
      "after backward: 0.2759224772453308\n",
      "after backward: 0.42346495389938354\n",
      "after backward: 0.26451417803764343\n",
      "after backward: 0.12045575678348541\n",
      "after backward: 0.018510349094867706\n",
      "after backward: 0.4610708951950073\n",
      "after backward: 0.7528976202011108\n",
      "after backward: 0.4573984444141388\n",
      "after backward: 0.22010907530784607\n",
      "after backward: 0.15185518562793732\n",
      "after backward: 0.21159526705741882\n",
      "after backward: 0.08416677266359329\n",
      "after backward: 0.4255961775779724\n",
      "after backward: 0.2679812014102936\n",
      "after backward: 0.3678608238697052\n",
      "after backward: 0.5199329853057861\n",
      "after backward: 0.28836360573768616\n",
      "after backward: 0.28157785534858704\n",
      "after backward: 0.194022074341774\n",
      "after backward: 0.2905670404434204\n",
      "after backward: 0.36476778984069824\n",
      "after backward: 0.6673392653465271\n",
      "after backward: 0.06447387486696243\n",
      "after backward: 0.3242431879043579\n",
      "after backward: 0.1433233916759491\n",
      "after backward: 0.1967715471982956\n",
      "after backward: 0.301296591758728\n",
      "after backward: 0.2000608742237091\n",
      "after backward: 0.17931553721427917\n",
      "after backward: 0.15579023957252502\n",
      "after backward: 0.2016392946243286\n",
      "after backward: 0.21992750465869904\n",
      "after backward: 0.25116315484046936\n",
      "after backward: 0.37211161851882935\n",
      "after backward: 0.3804580271244049\n",
      "after backward: 0.2531096637248993\n",
      "after backward: 0.23433737456798553\n",
      "after backward: 0.29749536514282227\n",
      "after backward: 0.2667967975139618\n",
      "after backward: 0.3563432991504669\n",
      "after backward: 0.37538647651672363\n",
      "after backward: 0.22912022471427917\n",
      "after backward: 0.5592378973960876\n",
      "after backward: 0.09989951550960541\n",
      "after backward: 0.3058614432811737\n",
      "after backward: 0.24638161063194275\n",
      "after backward: 0.04850349202752113\n",
      "after backward: 0.27999651432037354\n",
      "after backward: 0.15737003087997437\n",
      "after backward: 0.2029513120651245\n",
      "after backward: 0.20229710638523102\n",
      "after backward: 0.1858125776052475\n",
      "after backward: 0.4849506914615631\n",
      "after backward: 0.21392318606376648\n",
      "after backward: 0.14582203328609467\n",
      "after backward: 0.2275315225124359\n",
      "after backward: 0.08964697271585464\n",
      "after backward: 0.116420216858387\n",
      "after backward: 0.06067221611738205\n",
      "after backward: 0.2758583724498749\n",
      "after backward: 0.20182998478412628\n",
      "after backward: 0.2070983201265335\n",
      "after backward: 0.2572189271450043\n",
      "after backward: 0.2770616114139557\n",
      "after backward: 0.22501742839813232\n",
      "after backward: 0.1958262324333191\n",
      "after backward: 0.31142663955688477\n",
      "after backward: 0.7261635065078735\n",
      "after backward: 0.07165508717298508\n",
      "after backward: 0.2297821193933487\n",
      "after backward: 0.2120603621006012\n",
      "after backward: 0.3911163806915283\n",
      "after backward: 0.13078437745571136\n",
      "after backward: 0.32150503993034363\n",
      "after backward: 0.486763060092926\n",
      "after backward: 0.09413104504346848\n",
      "after backward: 0.4154847264289856\n",
      "after backward: 0.5011612772941589\n",
      "after backward: 0.17160563170909882\n",
      "after backward: 0.2754540741443634\n",
      "after backward: 0.3915134370326996\n",
      "after backward: 0.4800369143486023\n",
      "after backward: 0.050015855580568314\n",
      "after backward: 0.2612709105014801\n",
      "after backward: 0.1670377254486084\n",
      "after backward: 0.3037765622138977\n",
      "after backward: 0.7918980121612549\n",
      "after backward: 0.2581903636455536\n",
      "after backward: 0.24634931981563568\n",
      "after backward: 0.39065641164779663\n",
      "after backward: 0.4302249252796173\n",
      "after backward: 0.20583465695381165\n",
      "after backward: 0.2979479134082794\n",
      "after backward: 0.28185567259788513\n",
      "after backward: 0.11753268539905548\n",
      "after backward: 0.19384396076202393\n",
      "after backward: 0.2982396185398102\n",
      "after backward: 0.13068443536758423\n",
      "after backward: 0.571723222732544\n",
      "after backward: 0.19321230053901672\n",
      "after backward: 0.21145203709602356\n",
      "after backward: 0.34883421659469604\n",
      "after backward: 0.34385883808135986\n",
      "after backward: 0.44584396481513977\n",
      "after backward: 0.16996611654758453\n",
      "after backward: 0.26292020082473755\n",
      "after backward: 0.20460891723632812\n",
      "after backward: 0.21861298382282257\n",
      "after backward: 0.3794727921485901\n",
      "after backward: 0.13309994339942932\n",
      "after backward: 0.18255573511123657\n",
      "after backward: 0.08975386619567871\n",
      "after backward: 0.21040017902851105\n",
      "after backward: 0.3881194293498993\n",
      "after backward: 0.3520987927913666\n",
      "after backward: 0.30411389470100403\n",
      "after backward: 0.24610689282417297\n",
      "after backward: 0.26861050724983215\n",
      "after backward: 0.7978675961494446\n",
      "after backward: 0.17660385370254517\n",
      "after backward: 0.327538400888443\n",
      "after backward: 0.24869824945926666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after backward: 0.057256292551755905\n",
      "after backward: 0.30755484104156494\n",
      "after backward: 0.102604940533638\n",
      "after backward: 0.4680202305316925\n",
      "after backward: 0.37565845251083374\n",
      "after backward: 0.3067375719547272\n",
      "after backward: 0.194517120718956\n",
      "after backward: 0.40661224722862244\n",
      "after backward: 0.15022581815719604\n",
      "after backward: 0.2618543803691864\n",
      "after backward: 0.06553870439529419\n",
      "after backward: 0.4948265552520752\n",
      "after backward: 0.05641011893749237\n",
      "after backward: 0.2665047347545624\n",
      "after backward: 0.05750419944524765\n",
      "after backward: 0.34798988699913025\n",
      "after backward: 0.13552261888980865\n",
      "after backward: 0.26064935326576233\n",
      "after backward: 0.5246537923812866\n",
      "after backward: 0.6139988303184509\n",
      "after backward: 0.14062006771564484\n",
      "after backward: 0.3377191424369812\n",
      "after backward: 0.4448888897895813\n",
      "after backward: 0.0773424431681633\n",
      "after backward: 0.42858681082725525\n",
      "after backward: 0.49241510033607483\n",
      "after backward: 0.2543289363384247\n",
      "after backward: 0.279665470123291\n",
      "after backward: 0.43613460659980774\n",
      "after backward: 0.18091200292110443\n",
      "after backward: 0.2383068948984146\n",
      "after backward: 0.278552383184433\n",
      "after backward: 0.5743810534477234\n",
      "after backward: 0.3239923417568207\n",
      "after backward: 0.3893180787563324\n",
      "after backward: 0.46587586402893066\n",
      "after backward: 0.35525691509246826\n",
      "after backward: 0.2861453890800476\n",
      "after backward: 0.21805916726589203\n",
      "after backward: 0.27361512184143066\n",
      "after backward: 0.3225427269935608\n",
      "after backward: 0.14603255689144135\n",
      "after backward: 0.17636483907699585\n",
      "after backward: 0.12503354251384735\n",
      "after backward: 0.23570191860198975\n",
      "after backward: 0.4392493665218353\n",
      "after backward: 0.1986052691936493\n",
      "after backward: 0.10165305435657501\n",
      "after backward: 0.14111727476119995\n",
      "after backward: 0.0842563658952713\n",
      "after backward: 0.4848848581314087\n",
      "after backward: 0.27096667885780334\n",
      "after backward: 0.19567321240901947\n",
      "after backward: 0.26903173327445984\n",
      "after backward: 0.23873180150985718\n",
      "after backward: 0.45278868079185486\n",
      "after backward: 0.09235263615846634\n",
      "after backward: 0.4315338432788849\n",
      "after backward: 0.2002318948507309\n",
      "after backward: 0.15581560134887695\n",
      "after backward: 0.15347369015216827\n",
      "after backward: 0.04780317842960358\n",
      "after backward: 0.20366860926151276\n",
      "after backward: 0.2900077998638153\n",
      "after backward: 0.4151671528816223\n",
      "after backward: 0.26884353160858154\n",
      "after backward: 0.09464371204376221\n",
      "after backward: 0.26096946001052856\n",
      "after backward: 0.20327745378017426\n",
      "after backward: 0.16632524132728577\n",
      "after backward: 0.49137619137763977\n",
      "after backward: 0.22382773458957672\n",
      "after backward: 0.07671590894460678\n"
     ]
    }
   ],
   "source": [
    "train(model, train_dataloader, optimizer)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "28a641d4",
   "metadata": {},
   "source": [
    ">>> loss = nn.CrossEntropyLoss()\n",
    ">>> input = torch.randn(3, 5, requires_grad=True)\n",
    ">>> target = torch.empty(3, dtype=torch.long).random_(5)\n",
    ">>> output = loss(input, target)\n",
    ">>> output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20f7b78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pub",
   "language": "python",
   "name": "env_pub"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
