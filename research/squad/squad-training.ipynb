{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQuAD 데이터 입출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQuAD 데이터셋에 대한 모델 입출력은 아래와 같다."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "question = \"Who was Jim Henson?\"\n",
    "text = \"Jim Henson was a nice puppet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`question`과 `text`를 구분자(`[CLS]`, `[SEP]`)로 구분하여 아래와 같이 `inputs`을 만든다"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "inputs = ['[CLS]',\n",
    " 'who',\n",
    " 'was',\n",
    " 'jim',\n",
    " 'henson',\n",
    " '?',\n",
    " '[SEP]',\n",
    " 'jim',\n",
    " 'henson',\n",
    " 'was',\n",
    " 'a',\n",
    " 'nice',\n",
    " 'puppet',\n",
    " '[SEP]']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 입력에 대한 정답인 `start_position`과 `end_position`을 인덱스로 나타낸다."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "start_position = [10]\n",
    "end_position = [12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`inputs`의 10번째 토큰부터 12번째 토큰은 `['a', 'nice', 'puppet']`이며 `\"Who was Jim Hensom\"`에 대한 정답이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 및 DataLoader 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm, trange\n",
    "from transformers import BertTokenizer, BertForQuestionAnswering, AdamW\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from dataloader import SquadDataLoader\n",
    "from dataset import SquadDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache file exists\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SquadDataset('data', tokenizer, is_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = SquadDataLoader(train_dataset, batch_size=16, is_inference=False, shuffle=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "{'input_ids': tensor([[  101,  2040,  2001,  3958, 27227,  1029,   102,  3958, 27227,  2001,\n",
    "          1037,  3835, 13997,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 384]) torch.Size([16, 384]) torch.Size([16, 384]) torch.Size([16]) torch.Size([16, 384]) torch.Size([16]) torch.Size([16])\n",
      "torch.Size([16, 384]) torch.Size([16, 384]) torch.Size([16, 384]) torch.Size([16]) torch.Size([16, 384]) torch.Size([16]) torch.Size([16])\n",
      "torch.Size([16, 384]) torch.Size([16, 384]) torch.Size([16, 384]) torch.Size([16]) torch.Size([16, 384]) torch.Size([16]) torch.Size([16])\n",
      "torch.Size([16, 384]) torch.Size([16, 384]) torch.Size([16, 384]) torch.Size([16]) torch.Size([16, 384]) torch.Size([16]) torch.Size([16])\n",
      "torch.Size([16, 384]) torch.Size([16, 384]) torch.Size([16, 384]) torch.Size([16]) torch.Size([16, 384]) torch.Size([16]) torch.Size([16])\n",
      "torch.Size([16, 384]) torch.Size([16, 384]) torch.Size([16, 384]) torch.Size([16]) torch.Size([16, 384]) torch.Size([16]) torch.Size([16])\n",
      "torch.Size([16, 384]) torch.Size([16, 384]) torch.Size([16, 384]) torch.Size([16]) torch.Size([16, 384]) torch.Size([16]) torch.Size([16])\n",
      "torch.Size([16, 384]) torch.Size([16, 384]) torch.Size([16, 384]) torch.Size([16]) torch.Size([16, 384]) torch.Size([16]) torch.Size([16])\n",
      "torch.Size([16, 384]) torch.Size([16, 384]) torch.Size([16, 384]) torch.Size([16]) torch.Size([16, 384]) torch.Size([16]) torch.Size([16])\n",
      "torch.Size([16, 384]) torch.Size([16, 384]) torch.Size([16, 384]) torch.Size([16]) torch.Size([16, 384]) torch.Size([16]) torch.Size([16])\n",
      "torch.Size([16, 384]) torch.Size([16, 384]) torch.Size([16, 384]) torch.Size([16]) torch.Size([16, 384]) torch.Size([16]) torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(train_dataloader):\n",
    "    if i > 10:\n",
    "        break\n",
    "    input_ids, input_mask, segment_ids, cls_index, p_mask, start_positions, end_positions = batch\n",
    "    print(input_ids.shape, input_mask.shape, segment_ids.shape, cls_index.shape, p_mask.shape, start_positions.shape, end_positions.shape)\n",
    "#     inputs = {\n",
    "#         'input_ids': input_ids,\n",
    "#         'token_type_ids': segment_ids,\n",
    "#         'attention_mask': p_mask,\n",
    "#     }\n",
    "#     outputs = model(**inputs, start_positions=start_positions, end_positions=end_positions)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "모델을 학습하는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForQuestionAnswering: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: all CUDA-capable devices are busy or unavailable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-fe0228815666>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertForQuestionAnswering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert-base-uncased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/git/publish/env_pub/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \"\"\"\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/git/publish/env_pub/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/git/publish/env_pub/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/git/publish/env_pub/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/git/publish/env_pub/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/git/publish/env_pub/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \"\"\"\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: all CUDA-capable devices are busy or unavailable"
     ]
    }
   ],
   "source": [
    "model = BertForQuestionAnswering.from_pretrained('bert-base-uncased').cuda()\n",
    "model.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer와 Loss 함수는 가장 일반적인 것으로 정의했다.\n",
    "# 이 노트북 파일의 목적은 BERT를 이용해서 높은 성능의 모델을 간편하게 만들 수 있다는 것을 보여주기 위함이다.\n",
    "# Optimizer와 Loss를 최적화할 경우 좋은 성능이 나온 이유를 잘 설명할 수 없다.\n",
    "optimizer = AdamW(model.parameters(), lr = 2e-5, eps = 1e-8)\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer):\n",
    "    tbar = tqdm(dataloader, desc='Training', leave=True)\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    for i, batch in enumerate(tbar):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # cls_index와 p_mask는 XLNet 모델에 사용되므로 BERT에서는 사용하지 않는다.\n",
    "        input_ids, input_mask, segment_ids, cls_index, p_mask, start_positions, end_positions = batch\n",
    "        \n",
    "        # to cuda\n",
    "        input_ids = input_ids.cuda()\n",
    "        input_mask = input_mask.cuda()\n",
    "        segment_ids = segment_ids.cuda()\n",
    "        start_positions = start_positions.cuda()\n",
    "        end_positions = end_positions.cuda()\n",
    "        \n",
    "        # train model\n",
    "        #out = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        inputs = {\n",
    "            'input_ids': input_ids,\n",
    "            'token_type_ids': segment_ids,\n",
    "            'attention_mask': input_mask,\n",
    "        }\n",
    "        out = model(**inputs, start_positions=start_positions, end_positions=end_positions)\n",
    "        loss = out.loss\n",
    "\n",
    "        #print('before backward: {}'.format(loss))\n",
    "        loss.backward()\n",
    "        #torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        #print('after backward: {}'.format(loss))\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.data.item()\n",
    "        tbar.set_description(\"Average Loss = {:.4f})\".format(total_loss/(i+1)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = 1.1870): 100%|██████████| 8247/8247 [1:24:25<00:00,  1.63it/s]\n",
      "Average Loss = 0.6109): 100%|██████████| 8247/8247 [1:24:30<00:00,  1.63it/s]\n",
      "Average Loss = 0.2965): 100%|██████████| 8247/8247 [1:24:34<00:00,  1.63it/s]\n",
      "Average Loss = 0.1559): 100%|██████████| 8247/8247 [1:24:33<00:00,  1.63it/s]\n",
      "Average Loss = 0.1029): 100%|██████████| 8247/8247 [1:24:34<00:00,  1.63it/s]\n",
      "Average Loss = 0.0817): 100%|██████████| 8247/8247 [1:24:31<00:00,  1.63it/s]\n",
      "Average Loss = 0.0699): 100%|██████████| 8247/8247 [1:24:34<00:00,  1.63it/s]\n",
      "Average Loss = 0.0608): 100%|██████████| 8247/8247 [1:24:37<00:00,  1.62it/s]\n",
      "Average Loss = 0.0549): 100%|██████████| 8247/8247 [1:24:31<00:00,  1.63it/s]\n",
      "Average Loss = 0.0497): 100%|██████████| 8247/8247 [1:24:43<00:00,  1.62it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_epoch):\n",
    "    train(model, train_dataloader, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'squad_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Loss = 0.0495): 100%|██████████| 8247/8247 [1:24:22<00:00,  1.63it/s]\n"
     ]
    }
   ],
   "source": [
    "train(model, train_dataloader, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 jkfirst deep-learners 416M  6월 23 23:28 squad_model.bin\r\n"
     ]
    }
   ],
   "source": [
    "! ls -alh *.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "앞에서는 BERT를 이용해서 분류 모델을 만들었다. 이번 절에서는 BERT를 이용해서 질의응답 모델을 만들어보자. 앞 절에서와 마찬가지로 질의응답 모델을 만들기 위한 데이터셋과 데이터로더에 대한 설명은 생략하고, 학습에 사용할 데이터셋에 대한 설명과 질의응답 모델의 구조에 대해서 이야기해볼 예정이다. \n",
    "\n",
    "학습에 사용할 데이터셋은 SQuAD 2.0 데이터셋 이다. SQuAD는 Stanford Question Answering Dataset의 약자로 스텐포드 대학교에서 만든 질의응답 데이터셋이다. SQuAD 2.0 데이터셋은 하나의 문단과 그 문단에 대한 여러 개의 <질문, 답> 쌍으로 이루어져 있다. 데이터셋의 예시는 아래와 같다.\n",
    "<블록 시작>\n",
    "{\n",
    "    \"qas\": [\n",
    "\t\t{\"question\": \"When did Beyonce start becoming popular?\", \"id\": \"56be85543aeaaa14008c9063\", \"answers\": [{\"text\": \"in the late 1990s\", \"answer_start\": 269}], \"is_impossible\": false},\n",
    "\t\t{\"question\": \"What areas did Beyonce compete in when she was growing up?\", \"id\": \"56be85543aeaaa14008c9065\", \"answers\": [{\"text\": \"singing and dancing\", \"answer_start\": 207}], \"is_impossible\": false},\n",
    "\t\t{\"question\": \"When did Beyonce leave Destiny's Child and become a solo singer?\", \"id\": \"56be85543aeaaa14008c9066\", \"answers\": [{\"text\": \"2003\", \"answer_start\": 526}], \"is_impossible\": false},\n",
    "\t\t{\"question\": \"In what city and state did Beyonce  grow up? \", \"id\": \"56bf6b0f3aeaaa14008c9601\", \"answers\": [{\"text\": \"Houston, Texas\", \"answer_start\": 166}], \"is_impossible\": false},\n",
    "\t\t{\"question\": \"In which decade did Beyonce become famous?\", \"id\": \"56bf6b0f3aeaaa14008c9602\", \"answers\": [{\"text\": \"late 1990s\", \"answer_start\": 276}], \"is_impossible\": false},\n",
    "\t\t...\n",
    "\t\t{\"question\": \"What was the name of Beyonc\\u00e9's first solo album?\", \"id\": \"56d43ce42ccc5a1400d830b5\", \"answers\": [{\"text\": \"Dangerously in Love\", \"answer_start\": 505}], \"is_impossible\": false}],\n",
    "    \"context\": \"Beyonc\\u00e9 Giselle Knowles-Carter (/bi\\u02d0\\u02c8j\\u0252nse\\u026a/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyonc\\u00e9's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \\\"Crazy in Love\\\" and \\\"Baby Boy\\\".\"\n",
    "}\n",
    "<블록 끝>\n",
    "\n",
    "SQuAD 데이터셋은 json 파일 포멧으로 이루어져 있다. \"qas\"는 질의 응답 쌍 여러 개를 리스트 형태로 가지고 있고 그 질의 응답 쌍은 \"context\"로부터 추출한 것이다. \"qas\"는 \"question\", \"id\", \"answers\", \"is_impossible\" 키를 가지고 있다. \"question\"은 질문, \"id\"는 식별을 위한 ID값, \"answers\"은 질문에 대한 답이고, \"is_impossible\"은 \"context\"로부터 알아낼 수 있는 답인지에 대한 참/거짓 값이다. 가령 \"context\"로부터 답을 할 수 없는 질문에 경우 is_impossible은 true 값을 가진다. \"answers\"은 다시 \"text\"와 \"answer_start\"를 키로 갖는다. \"text\"는 질문에 대한 답을 \"context\"에서 찾아서 텍스트로 표현한 것이고, \"answer_start\"는 \"context\"에서 \"answers\"가 위치하는 인덱스의 시작값이다. 예를 들어서 위의 예시에서 {\"text\": \"in the late 1990s\", \"answer_start\": 269} 부분을 보면 \"in the late 1990s\"의 첫번째 문자인 \"i\"가 \"context\"의 269번째 문자에서 시작한다는 것이다.\n",
    "\n",
    "SQuAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_pub",
   "language": "python",
   "name": "env_pub"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
