{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a778fbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference to static quantization\n",
    "# https://rachitsingh.com/deep-learning-model-compression/\n",
    "# https://chowdera.com/2021/02/20210203170434983m.html\n",
    "# https://nenadmarkus.com/p/fusing-batchnorm-and-conv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4b07267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.quantization import QuantStub, DeQuantStub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c7df0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleNet(nn.Module):\n",
    "    def __init__(self, quantize_statically=False):\n",
    "        super(SampleNet, self).__init__()\n",
    "        self.quantize_statically = quantize_statically\n",
    "        in_channels = 112\n",
    "        out_channels = 112\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, groups=1, bias=False)\n",
    "        self.fc = nn.Linear(3, 2, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "        self.quant = QuantStub()\n",
    "        self.dequant = DeQuantStub()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.quantize_statically:\n",
    "            x = self.quant(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        if self.quantize_statically:\n",
    "            x = self.dequant(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21085447",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 1\n",
    "c = 3\n",
    "w = 112\n",
    "h = 112"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d411df64",
   "metadata": {},
   "source": [
    "## Dynamic Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baf4120f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SampleNet(quantize_statically=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5aa1c321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SampleNet(\n",
       "  (conv): Conv2d(112, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (fc): Linear(in_features=3, out_features=2, bias=False)\n",
       "  (relu): ReLU()\n",
       "  (quant): QuantStub()\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "081e2662",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_int8_dynamic = torch.quantization.quantize_dynamic(model, qconfig_spec=None, dtype=torch.qint8, mapping=None, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10a04b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SampleNet(\n",
       "  (conv): Conv2d(112, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (fc): DynamicQuantizedLinear(in_features=3, out_features=2, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "  (relu): ReLU()\n",
       "  (quant): QuantStub()\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_int8_dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5d68dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "x = torch.from_numpy(np.random.random((b, w, h, c))).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d353e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0231, 0.0000],\n",
       "          [0.0197, 0.0119],\n",
       "          [0.0000, 0.1756],\n",
       "          ...,\n",
       "          [0.0000, 0.0000],\n",
       "          [0.1062, 0.0000],\n",
       "          [0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0675],\n",
       "          [0.1083, 0.0508],\n",
       "          [0.0409, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000],\n",
       "          [0.0667, 0.0000],\n",
       "          [0.0000, 0.2212]],\n",
       "\n",
       "         [[0.0000, 0.0000],\n",
       "          [0.0000, 0.0029],\n",
       "          [0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000],\n",
       "          [0.0000, 0.0000],\n",
       "          [0.0000, 0.0000]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0000, 0.0000],\n",
       "          [0.0000, 0.0000],\n",
       "          [0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000],\n",
       "          [0.0000, 0.0000],\n",
       "          [0.0000, 0.0000]],\n",
       "\n",
       "         [[0.2278, 0.0000],\n",
       "          [0.0030, 0.0321],\n",
       "          [0.0000, 0.0170],\n",
       "          ...,\n",
       "          [0.0880, 0.0000],\n",
       "          [0.1663, 0.1369],\n",
       "          [0.0858, 0.0644]],\n",
       "\n",
       "         [[0.0000, 0.0000],\n",
       "          [0.0000, 0.0000],\n",
       "          [0.0000, 0.2061],\n",
       "          ...,\n",
       "          [0.0944, 0.0000],\n",
       "          [0.0000, 0.0000],\n",
       "          [0.0000, 0.0000]]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = model_int8_dynamic(x)\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ab39ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "o1_dynamic = model_int8_dynamic.conv(x)\n",
    "o2_dynamic = model_int8_dynamic.fc(o1_dynamic)\n",
    "o3_dynamic = model_int8_dynamic.relu(o2_dynamic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "585d7e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-2.7936e-01,  1.3857e-01,  3.3904e-02],\n",
       "          [-6.0530e-02, -3.7147e-02,  1.1386e-01],\n",
       "          [ 1.5183e-01, -2.6337e-01, -5.2935e-02],\n",
       "          ...,\n",
       "          [-4.2800e-01,  1.5016e-01, -2.2047e-01],\n",
       "          [-3.1539e-02,  3.9916e-01, -1.0503e-01],\n",
       "          [-4.6136e-02,  2.1197e-01, -2.8246e-01]],\n",
       "\n",
       "         [[ 9.8018e-02, -9.7160e-02, -9.3736e-02],\n",
       "          [ 1.0046e-01,  6.6256e-02,  1.8406e-01],\n",
       "          [-1.7397e-01,  1.8249e-01, -1.6140e-02],\n",
       "          ...,\n",
       "          [-1.4145e-01,  2.7818e-02, -2.2079e-01],\n",
       "          [-9.5429e-02,  1.8721e-01,  1.9807e-02],\n",
       "          [ 2.8730e-01, -2.2815e-01, -4.2962e-02]],\n",
       "\n",
       "         [[-5.8040e-01, -5.6354e-01, -5.6660e-01],\n",
       "          [-4.5702e-01, -7.6515e-01, -7.3578e-01],\n",
       "          [-8.6858e-01, -4.6947e-01, -6.8603e-01],\n",
       "          ...,\n",
       "          [-5.3551e-01, -4.0491e-01, -8.7254e-01],\n",
       "          [-1.0092e+00, -1.0788e+00, -4.9155e-01],\n",
       "          [-6.6138e-01, -7.2263e-01, -5.5642e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.7428e-01,  9.0049e-02, -1.8529e-01],\n",
       "          [-8.0417e-02,  1.4623e-01, -1.4011e-01],\n",
       "          [-1.7640e-01, -1.0422e-01, -4.1821e-01],\n",
       "          ...,\n",
       "          [-1.5213e-01, -4.5308e-02, -2.0108e-01],\n",
       "          [-3.0391e-01, -1.9792e-01, -2.3792e-01],\n",
       "          [-2.0492e-01, -1.4342e-01, -7.9017e-02]],\n",
       "\n",
       "         [[ 6.3269e-02,  3.7129e-01,  2.0078e-01],\n",
       "          [ 1.0819e-01,  1.0234e-02, -6.0917e-02],\n",
       "          [-1.6927e-01, -1.7959e-01,  1.0200e-01],\n",
       "          ...,\n",
       "          [ 1.9854e-01,  1.8370e-01, -3.9098e-02],\n",
       "          [ 3.8404e-01,  1.3337e-01,  1.4319e-01],\n",
       "          [ 5.2915e-04, -3.7216e-02,  2.6257e-01]],\n",
       "\n",
       "         [[-2.2042e-01, -4.1984e-02, -1.0517e-02],\n",
       "          [ 1.1923e-01,  3.1043e-02, -2.4860e-01],\n",
       "          [ 1.9294e-01, -2.3442e-01,  1.1297e-01],\n",
       "          ...,\n",
       "          [ 1.2969e-01,  2.4340e-01, -6.2893e-02],\n",
       "          [-3.9490e-01,  5.1460e-02, -8.6130e-03],\n",
       "          [-3.0566e-01, -5.0097e-02, -3.4750e-01]]]],\n",
       "       grad_fn=<MkldnnConvolutionBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o1_dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9637951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0231, -0.1790],\n",
       "          [ 0.0197,  0.0119],\n",
       "          [-0.1020,  0.1756],\n",
       "          ...,\n",
       "          [-0.0900, -0.2941],\n",
       "          [ 0.1062, -0.2146],\n",
       "          [-0.0323, -0.1607]],\n",
       "\n",
       "         [[-0.0585,  0.0675],\n",
       "          [ 0.1083,  0.0508],\n",
       "          [ 0.0409, -0.1639],\n",
       "          ...,\n",
       "          [-0.0988, -0.1083],\n",
       "          [ 0.0667, -0.1233],\n",
       "          [-0.0600,  0.2212]],\n",
       "\n",
       "         [[-0.5227, -0.1017],\n",
       "          [-0.6440,  0.0029],\n",
       "          [-0.5746, -0.2994],\n",
       "          ...,\n",
       "          [-0.5654, -0.2151],\n",
       "          [-0.7590, -0.0544],\n",
       "          [-0.5888, -0.0730]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0921, -0.2450],\n",
       "          [-0.0027, -0.1251],\n",
       "          [-0.2206, -0.1084],\n",
       "          ...,\n",
       "          [-0.1166, -0.0880],\n",
       "          [-0.2057, -0.0914],\n",
       "          [-0.1192, -0.0389]],\n",
       "\n",
       "         [[ 0.2278, -0.0978],\n",
       "          [ 0.0030,  0.0321],\n",
       "          [-0.0563,  0.0170],\n",
       "          ...,\n",
       "          [ 0.0880, -0.0068],\n",
       "          [ 0.1663,  0.1369],\n",
       "          [ 0.0858,  0.0644]],\n",
       "\n",
       "         [[-0.0563, -0.0878],\n",
       "          [-0.0614, -0.0103],\n",
       "          [-0.0169,  0.2061],\n",
       "          ...,\n",
       "          [ 0.0944, -0.0608],\n",
       "          [-0.0379, -0.2027],\n",
       "          [-0.1972, -0.1708]]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o2_dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45e805b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0231, 0.0000],\n",
       "          [0.0197, 0.0119],\n",
       "          [0.0000, 0.1756],\n",
       "          ...,\n",
       "          [0.0000, 0.0000],\n",
       "          [0.1062, 0.0000],\n",
       "          [0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0675],\n",
       "          [0.1083, 0.0508],\n",
       "          [0.0409, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000],\n",
       "          [0.0667, 0.0000],\n",
       "          [0.0000, 0.2212]],\n",
       "\n",
       "         [[0.0000, 0.0000],\n",
       "          [0.0000, 0.0029],\n",
       "          [0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000],\n",
       "          [0.0000, 0.0000],\n",
       "          [0.0000, 0.0000]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0000, 0.0000],\n",
       "          [0.0000, 0.0000],\n",
       "          [0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000],\n",
       "          [0.0000, 0.0000],\n",
       "          [0.0000, 0.0000]],\n",
       "\n",
       "         [[0.2278, 0.0000],\n",
       "          [0.0030, 0.0321],\n",
       "          [0.0000, 0.0170],\n",
       "          ...,\n",
       "          [0.0880, 0.0000],\n",
       "          [0.1663, 0.1369],\n",
       "          [0.0858, 0.0644]],\n",
       "\n",
       "         [[0.0000, 0.0000],\n",
       "          [0.0000, 0.0000],\n",
       "          [0.0000, 0.2061],\n",
       "          ...,\n",
       "          [0.0944, 0.0000],\n",
       "          [0.0000, 0.0000],\n",
       "          [0.0000, 0.0000]]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o3_dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb6e985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1afc867b",
   "metadata": {},
   "source": [
    "## Static Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "896f10bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SampleNet(quantize_statically=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7ad8737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SampleNet(\n",
       "  (conv): Conv2d(112, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (fc): Linear(in_features=3, out_features=2, bias=False)\n",
       "  (relu): ReLU()\n",
       "  (quant): QuantStub()\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faa3023",
   "metadata": {},
   "source": [
    "#### STEP 1. layer fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "224a0689",
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_model = torch.quantization.fuse_modules(model, [['fc', 'relu']], inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f3d292",
   "metadata": {},
   "source": [
    "#### STEP 2. setup config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "874cecce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_model.qconfig = torch.quantization.get_default_qconfig('fbgemm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd2fadbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SampleNet(\n",
       "  (conv): Conv2d(112, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (fc): LinearReLU(\n",
       "    (0): Linear(in_features=3, out_features=2, bias=False)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (relu): Identity()\n",
       "  (quant): QuantStub()\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fused_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b209cb30",
   "metadata": {},
   "source": [
    "#### STEP 3. Insert Observer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9f61112",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jkfirst/workspace/git/hello-transformer/env_hello/lib/python3.9/site-packages/torch/ao/quantization/observer.py:172: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "fused_model_with_observer = torch.quantization.prepare(fused_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb1b117a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SampleNet(\n",
       "  (conv): Conv2d(\n",
       "    112, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "    (activation_post_process): HistogramObserver()\n",
       "  )\n",
       "  (fc): LinearReLU(\n",
       "    (0): Linear(in_features=3, out_features=2, bias=False)\n",
       "    (1): ReLU()\n",
       "    (activation_post_process): HistogramObserver()\n",
       "  )\n",
       "  (relu): Identity()\n",
       "  (quant): QuantStub(\n",
       "    (activation_post_process): HistogramObserver()\n",
       "  )\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fused_model_with_observer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93fc15e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(inf)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fused_model_with_observer.fc.activation_post_process.min_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb393b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-inf)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fused_model_with_observer.fc.activation_post_process.max_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46afd95",
   "metadata": {},
   "source": [
    "#### STEP 4. calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab413af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(100):\n",
    "    inputs = torch.rand(b, w, h, c)\n",
    "    fused_model_with_observer(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8f5d145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fused_model_with_observer.fc.activation_post_process.min_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f564718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6285)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fused_model_with_observer.fc.activation_post_process.max_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43fd25e",
   "metadata": {},
   "source": [
    "#### STEP 5. convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36564e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jkfirst/workspace/git/hello-transformer/env_hello/lib/python3.9/site-packages/torch/ao/quantization/observer.py:886: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  src_bin_begin // dst_bin_width, 0, self.dst_nbins - 1\n",
      "/home/jkfirst/workspace/git/hello-transformer/env_hello/lib/python3.9/site-packages/torch/ao/quantization/observer.py:891: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  src_bin_end // dst_bin_width, 0, self.dst_nbins - 1\n"
     ]
    }
   ],
   "source": [
    "model_int8_static = torch.quantization.convert(fused_model_with_observer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80e9dfc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SampleNet(\n",
       "  (conv): QuantizedConv2d(112, 112, kernel_size=(1, 1), stride=(1, 1), scale=0.02259795553982258, zero_point=56, bias=False)\n",
       "  (fc): QuantizedLinearReLU(in_features=3, out_features=2, scale=0.004586605820804834, zero_point=0, qscheme=torch.per_channel_affine)\n",
       "  (relu): Identity()\n",
       "  (quant): Quantize(scale=tensor([0.0084]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "  (dequant): DeQuantize()\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_int8_static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "858b57ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "x = torch.from_numpy(np.random.random((b, w, h, c))).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8caa13a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0596, 0.0000],\n",
       "          [0.0000, 0.0780],\n",
       "          [0.1376, 0.0550],\n",
       "          ...,\n",
       "          [0.0780, 0.0734],\n",
       "          [0.0734, 0.0367],\n",
       "          [0.0183, 0.0000]],\n",
       "\n",
       "         [[0.2293, 0.1514],\n",
       "          [0.2431, 0.2706],\n",
       "          [0.1514, 0.2614],\n",
       "          ...,\n",
       "          [0.0826, 0.1238],\n",
       "          [0.0871, 0.0917],\n",
       "          [0.1147, 0.0871]],\n",
       "\n",
       "         [[0.0000, 0.0688],\n",
       "          [0.1651, 0.1330],\n",
       "          [0.0000, 0.0183],\n",
       "          ...,\n",
       "          [0.0046, 0.1468],\n",
       "          [0.0413, 0.0321],\n",
       "          [0.0550, 0.0138]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0642, 0.0000],\n",
       "          [0.1193, 0.0505],\n",
       "          [0.0917, 0.1514],\n",
       "          ...,\n",
       "          [0.1055, 0.0596],\n",
       "          [0.0963, 0.0092],\n",
       "          [0.1009, 0.0550]],\n",
       "\n",
       "         [[0.0963, 0.1514],\n",
       "          [0.1055, 0.0688],\n",
       "          [0.1881, 0.1514],\n",
       "          ...,\n",
       "          [0.1743, 0.2018],\n",
       "          [0.2752, 0.1651],\n",
       "          [0.0550, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000],\n",
       "          [0.0000, 0.0000],\n",
       "          [0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000],\n",
       "          [0.0000, 0.0000],\n",
       "          [0.0000, 0.0642]]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = model_int8_static(x)\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "22a50d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "o1_static = model_int8_static.quant(x)\n",
    "o2_static = model_int8_static.conv(o1_static)\n",
    "o3_static = model_int8_static.fc(o2_static)\n",
    "o4_static = model_int8_static.relu(o3_static)\n",
    "o5_static = model_int8_static.dequant(o4_static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "79c99f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 65,  33,  51],\n",
       "          [101,   1,  15],\n",
       "          [ 80,  99,  16],\n",
       "          ...,\n",
       "          [104,  13,  20],\n",
       "          [ 56,  93, 102],\n",
       "          [ 25,   9,  94]],\n",
       "\n",
       "         [[ 65,  94, 110],\n",
       "          [ 57,  55,  72],\n",
       "          [ 72,  60,  37],\n",
       "          ...,\n",
       "          [119,  30,  88],\n",
       "          [111,  70, 105],\n",
       "          [ 83,  42,  98]],\n",
       "\n",
       "         [[ 28, 110, 110],\n",
       "          [ 75,  61,  36],\n",
       "          [ 54,  86,  35],\n",
       "          ...,\n",
       "          [ 71,   3,  46],\n",
       "          [114,  27,  36],\n",
       "          [ 98,  69,   3]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 37,  51,  17],\n",
       "          [  5,   5, 107],\n",
       "          [ 62,  70,  80],\n",
       "          ...,\n",
       "          [ 63,  95,  18],\n",
       "          [ 30,  80,  19],\n",
       "          [118,  20, 113]],\n",
       "\n",
       "         [[111,  82,  26],\n",
       "          [ 80,  25,  85],\n",
       "          [ 34,  30,  13],\n",
       "          ...,\n",
       "          [ 87,  92,  95],\n",
       "          [ 88,  46, 104],\n",
       "          [  8, 117,  10]],\n",
       "\n",
       "         [[ 71,  50, 119],\n",
       "          [ 25,  25,  87],\n",
       "          [ 93,  43,  25],\n",
       "          ...,\n",
       "          [ 44,  36,  87],\n",
       "          [ 63,  50, 100],\n",
       "          [ 27, 104,  83]]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o1_static.int_repr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9c2b0361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[61, 50, 65],\n",
       "          [69, 68, 58],\n",
       "          [67, 62, 75],\n",
       "          ...,\n",
       "          [60, 63, 66],\n",
       "          [72, 63, 68],\n",
       "          [64, 54, 60]],\n",
       "\n",
       "         [[67, 70, 86],\n",
       "          [73, 84, 88],\n",
       "          [82, 88, 78],\n",
       "          ...,\n",
       "          [85, 76, 71],\n",
       "          [76, 70, 70],\n",
       "          [84, 71, 75]],\n",
       "\n",
       "         [[65, 67, 49],\n",
       "          [46, 63, 74],\n",
       "          [62, 61, 50],\n",
       "          ...,\n",
       "          [55, 71, 55],\n",
       "          [57, 59, 61],\n",
       "          [46, 53, 61]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[67, 58, 66],\n",
       "          [47, 56, 69],\n",
       "          [53, 69, 66],\n",
       "          ...,\n",
       "          [53, 59, 68],\n",
       "          [62, 57, 69],\n",
       "          [60, 61, 69]],\n",
       "\n",
       "         [[67, 73, 69],\n",
       "          [73, 66, 72],\n",
       "          [73, 73, 82],\n",
       "          ...,\n",
       "          [81, 81, 81],\n",
       "          [75, 73, 93],\n",
       "          [93, 63, 70]],\n",
       "\n",
       "         [[51, 50, 51],\n",
       "          [45, 50, 50],\n",
       "          [54, 36, 53],\n",
       "          ...,\n",
       "          [50, 45, 54],\n",
       "          [61, 46, 48],\n",
       "          [46, 61, 45]]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o2_static.int_repr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b6dcd92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[13,  0],\n",
       "          [ 0, 17],\n",
       "          [30, 12],\n",
       "          ...,\n",
       "          [17, 16],\n",
       "          [16,  8],\n",
       "          [ 4,  0]],\n",
       "\n",
       "         [[50, 33],\n",
       "          [53, 59],\n",
       "          [33, 57],\n",
       "          ...,\n",
       "          [18, 27],\n",
       "          [19, 20],\n",
       "          [25, 19]],\n",
       "\n",
       "         [[ 0, 15],\n",
       "          [36, 29],\n",
       "          [ 0,  4],\n",
       "          ...,\n",
       "          [ 1, 32],\n",
       "          [ 9,  7],\n",
       "          [12,  3]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[14,  0],\n",
       "          [26, 11],\n",
       "          [20, 33],\n",
       "          ...,\n",
       "          [23, 13],\n",
       "          [21,  2],\n",
       "          [22, 12]],\n",
       "\n",
       "         [[21, 33],\n",
       "          [23, 15],\n",
       "          [41, 33],\n",
       "          ...,\n",
       "          [38, 44],\n",
       "          [60, 36],\n",
       "          [12,  0]],\n",
       "\n",
       "         [[ 0,  0],\n",
       "          [ 0,  0],\n",
       "          [ 0,  0],\n",
       "          ...,\n",
       "          [ 0,  0],\n",
       "          [ 0,  0],\n",
       "          [ 0, 14]]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o3_static.int_repr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "90164cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[13,  0],\n",
       "          [ 0, 17],\n",
       "          [30, 12],\n",
       "          ...,\n",
       "          [17, 16],\n",
       "          [16,  8],\n",
       "          [ 4,  0]],\n",
       "\n",
       "         [[50, 33],\n",
       "          [53, 59],\n",
       "          [33, 57],\n",
       "          ...,\n",
       "          [18, 27],\n",
       "          [19, 20],\n",
       "          [25, 19]],\n",
       "\n",
       "         [[ 0, 15],\n",
       "          [36, 29],\n",
       "          [ 0,  4],\n",
       "          ...,\n",
       "          [ 1, 32],\n",
       "          [ 9,  7],\n",
       "          [12,  3]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[14,  0],\n",
       "          [26, 11],\n",
       "          [20, 33],\n",
       "          ...,\n",
       "          [23, 13],\n",
       "          [21,  2],\n",
       "          [22, 12]],\n",
       "\n",
       "         [[21, 33],\n",
       "          [23, 15],\n",
       "          [41, 33],\n",
       "          ...,\n",
       "          [38, 44],\n",
       "          [60, 36],\n",
       "          [12,  0]],\n",
       "\n",
       "         [[ 0,  0],\n",
       "          [ 0,  0],\n",
       "          [ 0,  0],\n",
       "          ...,\n",
       "          [ 0,  0],\n",
       "          [ 0,  0],\n",
       "          [ 0, 14]]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o4_static.int_repr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0b15e926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0596, 0.0000],\n",
       "          [0.0000, 0.0780],\n",
       "          [0.1376, 0.0550],\n",
       "          ...,\n",
       "          [0.0780, 0.0734],\n",
       "          [0.0734, 0.0367],\n",
       "          [0.0183, 0.0000]],\n",
       "\n",
       "         [[0.2293, 0.1514],\n",
       "          [0.2431, 0.2706],\n",
       "          [0.1514, 0.2614],\n",
       "          ...,\n",
       "          [0.0826, 0.1238],\n",
       "          [0.0871, 0.0917],\n",
       "          [0.1147, 0.0871]],\n",
       "\n",
       "         [[0.0000, 0.0688],\n",
       "          [0.1651, 0.1330],\n",
       "          [0.0000, 0.0183],\n",
       "          ...,\n",
       "          [0.0046, 0.1468],\n",
       "          [0.0413, 0.0321],\n",
       "          [0.0550, 0.0138]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0642, 0.0000],\n",
       "          [0.1193, 0.0505],\n",
       "          [0.0917, 0.1514],\n",
       "          ...,\n",
       "          [0.1055, 0.0596],\n",
       "          [0.0963, 0.0092],\n",
       "          [0.1009, 0.0550]],\n",
       "\n",
       "         [[0.0963, 0.1514],\n",
       "          [0.1055, 0.0688],\n",
       "          [0.1881, 0.1514],\n",
       "          ...,\n",
       "          [0.1743, 0.2018],\n",
       "          [0.2752, 0.1651],\n",
       "          [0.0550, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000],\n",
       "          [0.0000, 0.0000],\n",
       "          [0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000],\n",
       "          [0.0000, 0.0000],\n",
       "          [0.0000, 0.0642]]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o5_static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "93d5fd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.quantize_per_tensor(o2_static.data.cpu(), scale=0.02094164490699768, zero_point=61, dtype=torch.quint8).int_repr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c44204",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_hello",
   "language": "python",
   "name": "env_hello"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
